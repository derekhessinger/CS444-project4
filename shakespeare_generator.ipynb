{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "993849c2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Alex and Derek**\n",
    "\n",
    "Spring 2025\n",
    "\n",
    "CS 444: Deep Learning\n",
    "\n",
    "#### Project 4: Transformers\n",
    "\n",
    "In this final notebook, we will train larger GPTs on a large corpus of prose â€” the entire works of Shakespeare. Once trained, you will be able to prompt your GPTs with some text and it will generate text that appears to follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51fe93d6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(['seaborn-v0_8-colorblind', 'seaborn-v0_8-darkgrid'])\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "\n",
    "np.set_printoptions(suppress=True, precision=4)\n",
    "\n",
    "# Automatically reload your external source code\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c72772",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![Some fun](images/transformer4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b141eed",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Task 8. Preprocess a large corpus of text\n",
    "\n",
    "**NOTE:** This is no Task 7. It got removed due to time constraints.\n",
    "\n",
    "<!-- Let's write code to load in the works of Shakespeare (`shakespeare.txt`) and preprocess it so that we can try a transformer on the text. -->\n",
    "\n",
    "Run the test code in this section to make sure the works of Shakespeare (`shakespeare.txt`) are loaded and preprocessed properly for the transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d0c63dfe",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from preprocess_corpus import load_document, make_char2ind_map, make_seqs_and_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ca3a1c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 8a. Generate corpus and vocabulary\n",
    "\n",
    "<!-- In `preprocess_corpus.py`, implement the `load_document` function to load in the Shakespeare corpus and make the vocabulary. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6eeaa288",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vocabulary has 65 tokens and it should have 65.\n",
      "The vocabulary is (split up over multiple lines):\n",
      "['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L']\n",
      "['M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k']\n",
      "['l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "\n",
      "and it should be:\n",
      "['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L']\n",
      "['M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k']\n",
      "['l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "The corpus has 1115394 chars and it should have 1115394.\n",
      "-------------------------------------------------------\n",
      "The first 50 chars of the corpus is:\n",
      "First Citizen:\n",
      "Before we proceed any further, hear\n",
      "and it should be:\n",
      "First Citizen:\n",
      "Before we proceed any further, hear\n",
      "-------------------------------------------------------\n",
      "The last 50 chars of the corpus is:\n",
      "eep--die, rather; wink'st\n",
      "Whiles thou art waking.\n",
      "\n",
      "and it should be:\n",
      "eep--die, rather; wink'st\n",
      "Whiles thou art waking.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "corpus, vocab = load_document(path2data='shakespeare.txt')\n",
    "\n",
    "print(f'The vocabulary has {len(vocab)} tokens and it should have 65.')\n",
    "print(f'The vocabulary is (split up over multiple lines):\\n{vocab[:25]}\\n{vocab[25:50]}\\n{vocab[50:]}\\n')\n",
    "print('and it should be:')\n",
    "print(\"\"\"['\\\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L']\n",
    "['M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k']\n",
    "['l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\"\"\")\n",
    "\n",
    "print(f'The corpus has {len(corpus)} chars and it should have 1115394.')\n",
    "print(55*'-')\n",
    "print('The first 50 chars of the corpus is:')\n",
    "print(corpus[:50])\n",
    "print('and it should be:')\n",
    "print('''First Citizen:\n",
    "Before we proceed any further, hear''')\n",
    "print(55*'-')\n",
    "print('The last 50 chars of the corpus is:')\n",
    "print(corpus[-50:])\n",
    "print('and it should be:')\n",
    "print('''eep--die, rather; wink'st\n",
    "Whiles thou art waking.\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80fb62c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 8b. Create char2ind map\n",
    "\n",
    "<!-- In `preprocess_corpus.py`, implement the `make_char2ind_map` function and test it below. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b736a8c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of your char2ind map is 65 and it should be 65.\n",
      "Keys of your char2ind map:\n",
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "They should be \n",
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "Values of your char2ind map:\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64]\n",
      "They should be\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64]\n"
     ]
    }
   ],
   "source": [
    "char2ind_map = make_char2ind_map(vocab)\n",
    "\n",
    "print(f'Size of your char2ind map is {len(char2ind_map)} and it should be 65.')\n",
    "print('Keys of your char2ind map:')\n",
    "print(''.join(char2ind_map.keys()))\n",
    "print(\"They should be \\n\\n !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\")\n",
    "print('Values of your char2ind map:')\n",
    "print(list(char2ind_map.values()))\n",
    "print(\"They should be\")\n",
    "print('[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64]')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80262ef7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 8c. Create sequences of int-coded texts and labels\n",
    "\n",
    "<!-- In `preprocess_corpus.py`, implement the `make_seqs_and_labels` function, which should extract sequential `seq_len` long chunks (*our desired sequence length for the transformer*) to form the sequences on which we will train the transformer. The labels/targets are just the chars shifted by 1 (i.e. the next char in the corpus). -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a06b8247",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of your Shakespeare sequences is (4461, 250) and it should be (4461, 250).\n",
      "The shape of your Shakespeare labels is (4461, 250) and it should be (4461, 250).\n",
      "The first 15 int-coded tokens of the 1st few sequences are:\n",
      "[[18 47 56 57 58  1 15 47 58 47 64 43 52 10  0]\n",
      " [ 0 13 50 50 10  0 35 43  1 49 52 53 61  5 58]\n",
      " [ 1 41 47 58 47 64 43 52 57  6  1 58 46 43  1]\n",
      " [ 1 58 46 43  1 53 40 48 43 41 58  1 53 44  1]\n",
      " [31 43 41 53 52 42  1 15 47 58 47 64 43 52 10]]\n",
      "they should be:\n",
      "[[18 47 56 57 58  1 15 47 58 47 64 43 52 10  0]\n",
      " [ 0 13 50 50 10  0 35 43  1 49 52 53 61  5 58]\n",
      " [ 1 41 47 58 47 64 43 52 57  6  1 58 46 43  1]\n",
      " [ 1 58 46 43  1 53 40 48 43 41 58  1 53 44  1]\n",
      " [31 43 41 53 52 42  1 15 47 58 47 64 43 52 10]]\n",
      "The first 15 int-coded tokens of the last few sequences are:\n",
      "[[57 53  1 61 43 39 49 50 63  8  1 35 47 50 50]\n",
      " [ 6  0 16 53  1 52 53 58  1 53 51 47 58  1 58]\n",
      " [58 56 39 52 45 43  1 42 56 53 61 57 47 52 43]\n",
      " [42 56 53 54 54  5 42  6  1 39 57  1 40 63  1]\n",
      " [13 26 10  0 35 46 39 58  6  1 39 56 58  1 58]]\n",
      "they should be:\n",
      "[[57 53  1 61 43 39 49 50 63  8  1 35 47 50 50]\n",
      " [ 6  0 16 53  1 52 53 58  1 53 51 47 58  1 58]\n",
      " [58 56 39 52 45 43  1 42 56 53 61 57 47 52 43]\n",
      " [42 56 53 54 54  5 42  6  1 39 57  1 40 63  1]\n",
      " [13 26 10  0 35 46 39 58  6  1 39 56 58  1 58]]\n"
     ]
    }
   ],
   "source": [
    "seq_len = 250\n",
    "seqs, labels = make_seqs_and_labels(corpus, char2ind_map, seq_len=seq_len)\n",
    "\n",
    "print(f'The shape of your Shakespeare sequences is {seqs.shape} and it should be (4461, 250).')\n",
    "print(f'The shape of your Shakespeare labels is {labels.shape} and it should be (4461, 250).')\n",
    "print('The first 15 int-coded tokens of the 1st few sequences are:')\n",
    "print(seqs[:5, :15].numpy())\n",
    "print('they should be:')\n",
    "print('''[[18 47 56 57 58  1 15 47 58 47 64 43 52 10  0]\n",
    " [ 0 13 50 50 10  0 35 43  1 49 52 53 61  5 58]\n",
    " [ 1 41 47 58 47 64 43 52 57  6  1 58 46 43  1]\n",
    " [ 1 58 46 43  1 53 40 48 43 41 58  1 53 44  1]\n",
    " [31 43 41 53 52 42  1 15 47 58 47 64 43 52 10]]''')\n",
    "\n",
    "print('The first 15 int-coded tokens of the last few sequences are:')\n",
    "print(seqs[-5:, :15].numpy())\n",
    "print('they should be:')\n",
    "print('''[[57 53  1 61 43 39 49 50 63  8  1 35 47 50 50]\n",
    " [ 6  0 16 53  1 52 53 58  1 53 51 47 58  1 58]\n",
    " [58 56 39 52 45 43  1 42 56 53 61 57 47 52 43]\n",
    " [42 56 53 54 54  5 42  6  1 39 57  1 40 63  1]\n",
    " [13 26 10  0 35 46 39 58  6  1 39 56 58  1 58]]''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dc6bc9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 8d. Add padding char to dictionary\n",
    "\n",
    "**TODO:** Add the usual padding char (`'#'`) to the char2ind map to the next available int slot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "03d832fe",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 0,\n",
       " ' ': 1,\n",
       " '!': 2,\n",
       " '$': 3,\n",
       " '&': 4,\n",
       " \"'\": 5,\n",
       " ',': 6,\n",
       " '-': 7,\n",
       " '.': 8,\n",
       " '3': 9,\n",
       " ':': 10,\n",
       " ';': 11,\n",
       " '?': 12,\n",
       " 'A': 13,\n",
       " 'B': 14,\n",
       " 'C': 15,\n",
       " 'D': 16,\n",
       " 'E': 17,\n",
       " 'F': 18,\n",
       " 'G': 19,\n",
       " 'H': 20,\n",
       " 'I': 21,\n",
       " 'J': 22,\n",
       " 'K': 23,\n",
       " 'L': 24,\n",
       " 'M': 25,\n",
       " 'N': 26,\n",
       " 'O': 27,\n",
       " 'P': 28,\n",
       " 'Q': 29,\n",
       " 'R': 30,\n",
       " 'S': 31,\n",
       " 'T': 32,\n",
       " 'U': 33,\n",
       " 'V': 34,\n",
       " 'W': 35,\n",
       " 'X': 36,\n",
       " 'Y': 37,\n",
       " 'Z': 38,\n",
       " 'a': 39,\n",
       " 'b': 40,\n",
       " 'c': 41,\n",
       " 'd': 42,\n",
       " 'e': 43,\n",
       " 'f': 44,\n",
       " 'g': 45,\n",
       " 'h': 46,\n",
       " 'i': 47,\n",
       " 'j': 48,\n",
       " 'k': 49,\n",
       " 'l': 50,\n",
       " 'm': 51,\n",
       " 'n': 52,\n",
       " 'o': 53,\n",
       " 'p': 54,\n",
       " 'q': 55,\n",
       " 'r': 56,\n",
       " 's': 57,\n",
       " 't': 58,\n",
       " 'u': 59,\n",
       " 'v': 60,\n",
       " 'w': 61,\n",
       " 'x': 62,\n",
       " 'y': 63,\n",
       " 'z': 64,\n",
       " '#': 64}"
      ]
     },
     "execution_count": 24,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add padding char to dictionary\n",
    "char2ind_map['#'] = len(char2ind_map)-1\n",
    "char2ind_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df99ac1",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Task 9. Train GPT on Shakespeare\n",
    "\n",
    "Now we are ready to train a GPT on the works of Shakespeare!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd25755e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 9a. Build `GPTMini6`\n",
    "\n",
    "We will use a deeper transformer called `GPTMini6` for training on the Shakespeare corpus. Build the neural network then check the summary below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "42d91153",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from gpts import GPTMini6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c69735c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "Dense layer output(Output_layer) shape: [1, 15, 9]\n",
      "Transformer_Block_5:\n",
      "\tTransformer_Block_5_MLP:\n",
      "\tDropout layer output(Transformer_Block_5_MLP_Dropout) shape: [1, 15, 384]\n",
      "\tDense layer output(Transformer_Block_5_MLP_Dense2) shape: [1, 15, 384]\n",
      "\tDense layer output(Transformer_Block_5_MLP_Dense1) shape: [1, 15, 1536]\n",
      "\tTransformer_Block_5_MHA:\n",
      "\tDropout layer output(Transformer_Block_5_MHA_Dropout) shape: [1, 15, 384]\n",
      "\tDense layer output(Transformer_Block_5_MHA_Dense) shape: [1, 15, 384]\n",
      "\tTransformer_Block_5_MHA_Attention:\n",
      "\tDropout layer output(attention_dropout) shape: [1, 6, 15, 15]\n",
      "\tTransformer_Block_5_MHA_QKV:\n",
      "\tDense layer output(QKVBlock_Value) shape: [1, 15, 384]\n",
      "\tDense layer output(QKVBlock_Key) shape: [1, 15, 384]\n",
      "\tDense layer output(QKVBlock_Query) shape: [1, 15, 384]\n",
      "Transformer_Block_4:\n",
      "\tTransformer_Block_4_MLP:\n",
      "\tDropout layer output(Transformer_Block_4_MLP_Dropout) shape: [1, 15, 384]\n",
      "\tDense layer output(Transformer_Block_4_MLP_Dense2) shape: [1, 15, 384]\n",
      "\tDense layer output(Transformer_Block_4_MLP_Dense1) shape: [1, 15, 1536]\n",
      "\tTransformer_Block_4_MHA:\n",
      "\tDropout layer output(Transformer_Block_4_MHA_Dropout) shape: [1, 15, 384]\n",
      "\tDense layer output(Transformer_Block_4_MHA_Dense) shape: [1, 15, 384]\n",
      "\tTransformer_Block_4_MHA_Attention:\n",
      "\tDropout layer output(attention_dropout) shape: [1, 6, 15, 15]\n",
      "\tTransformer_Block_4_MHA_QKV:\n",
      "\tDense layer output(QKVBlock_Value) shape: [1, 15, 384]\n",
      "\tDense layer output(QKVBlock_Key) shape: [1, 15, 384]\n",
      "\tDense layer output(QKVBlock_Query) shape: [1, 15, 384]\n",
      "Transformer_Block_3:\n",
      "\tTransformer_Block_3_MLP:\n",
      "\tDropout layer output(Transformer_Block_3_MLP_Dropout) shape: [1, 15, 384]\n",
      "\tDense layer output(Transformer_Block_3_MLP_Dense2) shape: [1, 15, 384]\n",
      "\tDense layer output(Transformer_Block_3_MLP_Dense1) shape: [1, 15, 1536]\n",
      "\tTransformer_Block_3_MHA:\n",
      "\tDropout layer output(Transformer_Block_3_MHA_Dropout) shape: [1, 15, 384]\n",
      "\tDense layer output(Transformer_Block_3_MHA_Dense) shape: [1, 15, 384]\n",
      "\tTransformer_Block_3_MHA_Attention:\n",
      "\tDropout layer output(attention_dropout) shape: [1, 6, 15, 15]\n",
      "\tTransformer_Block_3_MHA_QKV:\n",
      "\tDense layer output(QKVBlock_Value) shape: [1, 15, 384]\n",
      "\tDense layer output(QKVBlock_Key) shape: [1, 15, 384]\n",
      "\tDense layer output(QKVBlock_Query) shape: [1, 15, 384]\n",
      "Transformer_Block_2:\n",
      "\tTransformer_Block_2_MLP:\n",
      "\tDropout layer output(Transformer_Block_2_MLP_Dropout) shape: [1, 15, 384]\n",
      "\tDense layer output(Transformer_Block_2_MLP_Dense2) shape: [1, 15, 384]\n",
      "\tDense layer output(Transformer_Block_2_MLP_Dense1) shape: [1, 15, 1536]\n",
      "\tTransformer_Block_2_MHA:\n",
      "\tDropout layer output(Transformer_Block_2_MHA_Dropout) shape: [1, 15, 384]\n",
      "\tDense layer output(Transformer_Block_2_MHA_Dense) shape: [1, 15, 384]\n",
      "\tTransformer_Block_2_MHA_Attention:\n",
      "\tDropout layer output(attention_dropout) shape: [1, 6, 15, 15]\n",
      "\tTransformer_Block_2_MHA_QKV:\n",
      "\tDense layer output(QKVBlock_Value) shape: [1, 15, 384]\n",
      "\tDense layer output(QKVBlock_Key) shape: [1, 15, 384]\n",
      "\tDense layer output(QKVBlock_Query) shape: [1, 15, 384]\n",
      "Transformer_Block_1:\n",
      "\tTransformer_Block_1_MLP:\n",
      "\tDropout layer output(Transformer_Block_1_MLP_Dropout) shape: [1, 15, 384]\n",
      "\tDense layer output(Transformer_Block_1_MLP_Dense2) shape: [1, 15, 384]\n",
      "\tDense layer output(Transformer_Block_1_MLP_Dense1) shape: [1, 15, 1536]\n",
      "\tTransformer_Block_1_MHA:\n",
      "\tDropout layer output(Transformer_Block_1_MHA_Dropout) shape: [1, 15, 384]\n",
      "\tDense layer output(Transformer_Block_1_MHA_Dense) shape: [1, 15, 384]\n",
      "\tTransformer_Block_1_MHA_Attention:\n",
      "\tDropout layer output(attention_dropout) shape: [1, 6, 15, 15]\n",
      "\tTransformer_Block_1_MHA_QKV:\n",
      "\tDense layer output(QKVBlock_Value) shape: [1, 15, 384]\n",
      "\tDense layer output(QKVBlock_Key) shape: [1, 15, 384]\n",
      "\tDense layer output(QKVBlock_Query) shape: [1, 15, 384]\n",
      "Transformer_Block_0:\n",
      "\tTransformer_Block_0_MLP:\n",
      "\tDropout layer output(Transformer_Block_0_MLP_Dropout) shape: [1, 15, 384]\n",
      "\tDense layer output(Transformer_Block_0_MLP_Dense2) shape: [1, 15, 384]\n",
      "\tDense layer output(Transformer_Block_0_MLP_Dense1) shape: [1, 15, 1536]\n",
      "\tTransformer_Block_0_MHA:\n",
      "\tDropout layer output(Transformer_Block_0_MHA_Dropout) shape: [1, 15, 384]\n",
      "\tDense layer output(Transformer_Block_0_MHA_Dense) shape: [1, 15, 384]\n",
      "\tTransformer_Block_0_MHA_Attention:\n",
      "\tDropout layer output(attention_dropout) shape: [1, 6, 15, 15]\n",
      "\tTransformer_Block_0_MHA_QKV:\n",
      "\tDense layer output(QKVBlock_Value) shape: [1, 15, 384]\n",
      "\tDense layer output(QKVBlock_Key) shape: [1, 15, 384]\n",
      "\tDense layer output(QKVBlock_Query) shape: [1, 15, 384]\n",
      "Positional_Encoding_Block_0:\n",
      "\tDropout layer output(Positional_Encoding_Block_0_Dropout) shape: [1, 15, 384]\n",
      "\tPositional encoding layer output(Positional_Encoding_Block_0_PE) shape: [1, 15, 384]\n",
      "Embedding layer output(Embedding_Layer_0) shape: [1, 15, 384]\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# TODO: Set padding_char_enc to the int coded padding token below\n",
    "padding_char_enc = char2ind_map['#']\n",
    "myminigpt = GPTMini6(vocab_sz=9, seq_len=15, padding_char_enc=padding_char_enc)\n",
    "myminigpt.compile(loss='temporal_cross_entropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252ddd95",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The above cell should output:\n",
    "\n",
    "```\n",
    "---------------------------------------------------------------------------\n",
    "Dense layer output(output) shape: [1, 15, 9]\n",
    "TransformerBlock_5:\n",
    "\tTransformerBlock_5/MLP:\n",
    "\tDropout layer output(TransformerBlock_5/MLP/dropout) shape: [1, 15, 384]\n",
    "\tDense layer output(TransformerBlock_5/MLP/dense_1) shape: [1, 15, 384]\n",
    "\tDense layer output(TransformerBlock_5/MLP/dense_0) shape: [1, 15, 1536]\n",
    "\tTransformerBlock_5/multihead_attention:\n",
    "\tDropout layer output(TransformerBlock_5/multihead_attention/dropout) shape: [1, 15, 384]\n",
    "\tDense layer output(TransformerBlock_5/multihead_attention/dense_1) shape: [1, 15, 384]\n",
    "\tTransformerBlock_5/multihead_attention/attention:\n",
    "\tDropout layer output(TransformerBlock_5/multihead_attention/attention/dropout) shape: [1, 6, 15, 15]\n",
    "\tTransformerBlock_5/multihead_attention/qkv_block:\n",
    "\tDense layer output(TransformerBlock_5/multihead_attention/qkv_block/dense_v) shape: [1, 15, 384]\n",
    "\tDense layer output(TransformerBlock_5/multihead_attention/qkv_block/dense_k) shape: [1, 15, 384]\n",
    "\tDense layer output(TransformerBlock_5/multihead_attention/qkv_block/dense_q) shape: [1, 15, 384]\n",
    "TransformerBlock_4:\n",
    "\tTransformerBlock_4/MLP:\n",
    "\tDropout layer output(TransformerBlock_4/MLP/dropout) shape: [1, 15, 384]\n",
    "\tDense layer output(TransformerBlock_4/MLP/dense_1) shape: [1, 15, 384]\n",
    "\tDense layer output(TransformerBlock_4/MLP/dense_0) shape: [1, 15, 1536]\n",
    "\tTransformerBlock_4/multihead_attention:\n",
    "\tDropout layer output(TransformerBlock_4/multihead_attention/dropout) shape: [1, 15, 384]\n",
    "\tDense layer output(TransformerBlock_4/multihead_attention/dense_1) shape: [1, 15, 384]\n",
    "\tTransformerBlock_4/multihead_attention/attention:\n",
    "\tDropout layer output(TransformerBlock_4/multihead_attention/attention/dropout) shape: [1, 6, 15, 15]\n",
    "\tTransformerBlock_4/multihead_attention/qkv_block:\n",
    "\tDense layer output(TransformerBlock_4/multihead_attention/qkv_block/dense_v) shape: [1, 15, 384]\n",
    "\tDense layer output(TransformerBlock_4/multihead_attention/qkv_block/dense_k) shape: [1, 15, 384]\n",
    "\tDense layer output(TransformerBlock_4/multihead_attention/qkv_block/dense_q) shape: [1, 15, 384]\n",
    "TransformerBlock_3:\n",
    "\tTransformerBlock_3/MLP:\n",
    "\tDropout layer output(TransformerBlock_3/MLP/dropout) shape: [1, 15, 384]\n",
    "\tDense layer output(TransformerBlock_3/MLP/dense_1) shape: [1, 15, 384]\n",
    "\tDense layer output(TransformerBlock_3/MLP/dense_0) shape: [1, 15, 1536]\n",
    "\tTransformerBlock_3/multihead_attention:\n",
    "\tDropout layer output(TransformerBlock_3/multihead_attention/dropout) shape: [1, 15, 384]\n",
    "\tDense layer output(TransformerBlock_3/multihead_attention/dense_1) shape: [1, 15, 384]\n",
    "\tTransformerBlock_3/multihead_attention/attention:\n",
    "\tDropout layer output(TransformerBlock_3/multihead_attention/attention/dropout) shape: [1, 6, 15, 15]\n",
    "\tTransformerBlock_3/multihead_attention/qkv_block:\n",
    "\tDense layer output(TransformerBlock_3/multihead_attention/qkv_block/dense_v) shape: [1, 15, 384]\n",
    "\tDense layer output(TransformerBlock_3/multihead_attention/qkv_block/dense_k) shape: [1, 15, 384]\n",
    "\tDense layer output(TransformerBlock_3/multihead_attention/qkv_block/dense_q) shape: [1, 15, 384]\n",
    "TransformerBlock_2:\n",
    "\tTransformerBlock_2/MLP:\n",
    "\tDropout layer output(TransformerBlock_2/MLP/dropout) shape: [1, 15, 384]\n",
    "\tDense layer output(TransformerBlock_2/MLP/dense_1) shape: [1, 15, 384]\n",
    "\tDense layer output(TransformerBlock_2/MLP/dense_0) shape: [1, 15, 1536]\n",
    "\tTransformerBlock_2/multihead_attention:\n",
    "\tDropout layer output(TransformerBlock_2/multihead_attention/dropout) shape: [1, 15, 384]\n",
    "\tDense layer output(TransformerBlock_2/multihead_attention/dense_1) shape: [1, 15, 384]\n",
    "\tTransformerBlock_2/multihead_attention/attention:\n",
    "\tDropout layer output(TransformerBlock_2/multihead_attention/attention/dropout) shape: [1, 6, 15, 15]\n",
    "\tTransformerBlock_2/multihead_attention/qkv_block:\n",
    "\tDense layer output(TransformerBlock_2/multihead_attention/qkv_block/dense_v) shape: [1, 15, 384]\n",
    "\tDense layer output(TransformerBlock_2/multihead_attention/qkv_block/dense_k) shape: [1, 15, 384]\n",
    "\tDense layer output(TransformerBlock_2/multihead_attention/qkv_block/dense_q) shape: [1, 15, 384]\n",
    "TransformerBlock_1:\n",
    "\tTransformerBlock_1/MLP:\n",
    "\tDropout layer output(TransformerBlock_1/MLP/dropout) shape: [1, 15, 384]\n",
    "\tDense layer output(TransformerBlock_1/MLP/dense_1) shape: [1, 15, 384]\n",
    "\tDense layer output(TransformerBlock_1/MLP/dense_0) shape: [1, 15, 1536]\n",
    "\tTransformerBlock_1/multihead_attention:\n",
    "\tDropout layer output(TransformerBlock_1/multihead_attention/dropout) shape: [1, 15, 384]\n",
    "\tDense layer output(TransformerBlock_1/multihead_attention/dense_1) shape: [1, 15, 384]\n",
    "\tTransformerBlock_1/multihead_attention/attention:\n",
    "\tDropout layer output(TransformerBlock_1/multihead_attention/attention/dropout) shape: [1, 6, 15, 15]\n",
    "\tTransformerBlock_1/multihead_attention/qkv_block:\n",
    "\tDense layer output(TransformerBlock_1/multihead_attention/qkv_block/dense_v) shape: [1, 15, 384]\n",
    "\tDense layer output(TransformerBlock_1/multihead_attention/qkv_block/dense_k) shape: [1, 15, 384]\n",
    "\tDense layer output(TransformerBlock_1/multihead_attention/qkv_block/dense_q) shape: [1, 15, 384]\n",
    "TransformerBlock_0:\n",
    "\tTransformerBlock_0/MLP:\n",
    "\tDropout layer output(TransformerBlock_0/MLP/dropout) shape: [1, 15, 384]\n",
    "\tDense layer output(TransformerBlock_0/MLP/dense_1) shape: [1, 15, 384]\n",
    "\tDense layer output(TransformerBlock_0/MLP/dense_0) shape: [1, 15, 1536]\n",
    "\tTransformerBlock_0/multihead_attention:\n",
    "\tDropout layer output(TransformerBlock_0/multihead_attention/dropout) shape: [1, 15, 384]\n",
    "\tDense layer output(TransformerBlock_0/multihead_attention/dense_1) shape: [1, 15, 384]\n",
    "\tTransformerBlock_0/multihead_attention/attention:\n",
    "\tDropout layer output(TransformerBlock_0/multihead_attention/attention/dropout) shape: [1, 6, 15, 15]\n",
    "\tTransformerBlock_0/multihead_attention/qkv_block:\n",
    "\tDense layer output(TransformerBlock_0/multihead_attention/qkv_block/dense_v) shape: [1, 15, 384]\n",
    "\tDense layer output(TransformerBlock_0/multihead_attention/qkv_block/dense_k) shape: [1, 15, 384]\n",
    "\tDense layer output(TransformerBlock_0/multihead_attention/qkv_block/dense_q) shape: [1, 15, 384]\n",
    "PositionalEncodingBlock:\n",
    "\tDropout layer output(PositionalEncodingBlock/dropout) shape: [1, 15, 384]\n",
    "\tPositional encoding layer output(PositionalEncodingBlock/positional_enc_layer) shape: [1, 15, 384]\n",
    "Embedding layer output(EmbeddingLayer) shape: [1, 15, 384]\n",
    "---------------------------------------------------------------------------\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86680bd4",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 9b. Train `GPTMini6` on the works of Shakespeare\n",
    "\n",
    "Use default hyperparameters except for the following:\n",
    "- For the validation set, use the 1st 200 sequences. For the training set, use all sequences beyond the 1st 200.\n",
    "- Batch size of `64`.\n",
    "- Patience of `15`.\n",
    "- Learning rate decay patience of `9`.\n",
    "- Learning rate should be allowed to decay no more than `3` times.\n",
    "- Limit training to `100` epochs maximum.\n",
    "\n",
    "Make a well-labeled plot showing the **training and validation loss** over the course of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9658f5d5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "Dense layer output(Output_layer) shape: [1, 128, 65]\n",
      "Transformer_Block_5:\n",
      "\tTransformer_Block_5_MLP:\n",
      "\tDropout layer output(Transformer_Block_5_MLP_Dropout) shape: [1, 128, 384]\n",
      "\tDense layer output(Transformer_Block_5_MLP_Dense2) shape: [1, 128, 384]\n",
      "\tDense layer output(Transformer_Block_5_MLP_Dense1) shape: [1, 128, 1536]\n",
      "\tTransformer_Block_5_MHA:\n",
      "\tDropout layer output(Transformer_Block_5_MHA_Dropout) shape: [1, 128, 384]\n",
      "\tDense layer output(Transformer_Block_5_MHA_Dense) shape: [1, 128, 384]\n",
      "\tTransformer_Block_5_MHA_Attention:\n",
      "\tDropout layer output(attention_dropout) shape: [1, 6, 128, 128]\n",
      "\tTransformer_Block_5_MHA_QKV:\n",
      "\tDense layer output(QKVBlock_Value) shape: [1, 128, 384]\n",
      "\tDense layer output(QKVBlock_Key) shape: [1, 128, 384]\n",
      "\tDense layer output(QKVBlock_Query) shape: [1, 128, 384]\n",
      "Transformer_Block_4:\n",
      "\tTransformer_Block_4_MLP:\n",
      "\tDropout layer output(Transformer_Block_4_MLP_Dropout) shape: [1, 128, 384]\n",
      "\tDense layer output(Transformer_Block_4_MLP_Dense2) shape: [1, 128, 384]\n",
      "\tDense layer output(Transformer_Block_4_MLP_Dense1) shape: [1, 128, 1536]\n",
      "\tTransformer_Block_4_MHA:\n",
      "\tDropout layer output(Transformer_Block_4_MHA_Dropout) shape: [1, 128, 384]\n",
      "\tDense layer output(Transformer_Block_4_MHA_Dense) shape: [1, 128, 384]\n",
      "\tTransformer_Block_4_MHA_Attention:\n",
      "\tDropout layer output(attention_dropout) shape: [1, 6, 128, 128]\n",
      "\tTransformer_Block_4_MHA_QKV:\n",
      "\tDense layer output(QKVBlock_Value) shape: [1, 128, 384]\n",
      "\tDense layer output(QKVBlock_Key) shape: [1, 128, 384]\n",
      "\tDense layer output(QKVBlock_Query) shape: [1, 128, 384]\n",
      "Transformer_Block_3:\n",
      "\tTransformer_Block_3_MLP:\n",
      "\tDropout layer output(Transformer_Block_3_MLP_Dropout) shape: [1, 128, 384]\n",
      "\tDense layer output(Transformer_Block_3_MLP_Dense2) shape: [1, 128, 384]\n",
      "\tDense layer output(Transformer_Block_3_MLP_Dense1) shape: [1, 128, 1536]\n",
      "\tTransformer_Block_3_MHA:\n",
      "\tDropout layer output(Transformer_Block_3_MHA_Dropout) shape: [1, 128, 384]\n",
      "\tDense layer output(Transformer_Block_3_MHA_Dense) shape: [1, 128, 384]\n",
      "\tTransformer_Block_3_MHA_Attention:\n",
      "\tDropout layer output(attention_dropout) shape: [1, 6, 128, 128]\n",
      "\tTransformer_Block_3_MHA_QKV:\n",
      "\tDense layer output(QKVBlock_Value) shape: [1, 128, 384]\n",
      "\tDense layer output(QKVBlock_Key) shape: [1, 128, 384]\n",
      "\tDense layer output(QKVBlock_Query) shape: [1, 128, 384]\n",
      "Transformer_Block_2:\n",
      "\tTransformer_Block_2_MLP:\n",
      "\tDropout layer output(Transformer_Block_2_MLP_Dropout) shape: [1, 128, 384]\n",
      "\tDense layer output(Transformer_Block_2_MLP_Dense2) shape: [1, 128, 384]\n",
      "\tDense layer output(Transformer_Block_2_MLP_Dense1) shape: [1, 128, 1536]\n",
      "\tTransformer_Block_2_MHA:\n",
      "\tDropout layer output(Transformer_Block_2_MHA_Dropout) shape: [1, 128, 384]\n",
      "\tDense layer output(Transformer_Block_2_MHA_Dense) shape: [1, 128, 384]\n",
      "\tTransformer_Block_2_MHA_Attention:\n",
      "\tDropout layer output(attention_dropout) shape: [1, 6, 128, 128]\n",
      "\tTransformer_Block_2_MHA_QKV:\n",
      "\tDense layer output(QKVBlock_Value) shape: [1, 128, 384]\n",
      "\tDense layer output(QKVBlock_Key) shape: [1, 128, 384]\n",
      "\tDense layer output(QKVBlock_Query) shape: [1, 128, 384]\n",
      "Transformer_Block_1:\n",
      "\tTransformer_Block_1_MLP:\n",
      "\tDropout layer output(Transformer_Block_1_MLP_Dropout) shape: [1, 128, 384]\n",
      "\tDense layer output(Transformer_Block_1_MLP_Dense2) shape: [1, 128, 384]\n",
      "\tDense layer output(Transformer_Block_1_MLP_Dense1) shape: [1, 128, 1536]\n",
      "\tTransformer_Block_1_MHA:\n",
      "\tDropout layer output(Transformer_Block_1_MHA_Dropout) shape: [1, 128, 384]\n",
      "\tDense layer output(Transformer_Block_1_MHA_Dense) shape: [1, 128, 384]\n",
      "\tTransformer_Block_1_MHA_Attention:\n",
      "\tDropout layer output(attention_dropout) shape: [1, 6, 128, 128]\n",
      "\tTransformer_Block_1_MHA_QKV:\n",
      "\tDense layer output(QKVBlock_Value) shape: [1, 128, 384]\n",
      "\tDense layer output(QKVBlock_Key) shape: [1, 128, 384]\n",
      "\tDense layer output(QKVBlock_Query) shape: [1, 128, 384]\n",
      "Transformer_Block_0:\n",
      "\tTransformer_Block_0_MLP:\n",
      "\tDropout layer output(Transformer_Block_0_MLP_Dropout) shape: [1, 128, 384]\n",
      "\tDense layer output(Transformer_Block_0_MLP_Dense2) shape: [1, 128, 384]\n",
      "\tDense layer output(Transformer_Block_0_MLP_Dense1) shape: [1, 128, 1536]\n",
      "\tTransformer_Block_0_MHA:\n",
      "\tDropout layer output(Transformer_Block_0_MHA_Dropout) shape: [1, 128, 384]\n",
      "\tDense layer output(Transformer_Block_0_MHA_Dense) shape: [1, 128, 384]\n",
      "\tTransformer_Block_0_MHA_Attention:\n",
      "\tDropout layer output(attention_dropout) shape: [1, 6, 128, 128]\n",
      "\tTransformer_Block_0_MHA_QKV:\n",
      "\tDense layer output(QKVBlock_Value) shape: [1, 128, 384]\n",
      "\tDense layer output(QKVBlock_Key) shape: [1, 128, 384]\n",
      "\tDense layer output(QKVBlock_Query) shape: [1, 128, 384]\n",
      "Positional_Encoding_Block_0:\n",
      "\tDropout layer output(Positional_Encoding_Block_0_Dropout) shape: [1, 128, 384]\n",
      "\tPositional encoding layer output(Positional_Encoding_Block_0_PE) shape: [1, 128, 384]\n",
      "Embedding layer output(Embedding_Layer_0) shape: [1, 128, 384]\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Create sequences and labels\n",
    "seq_len = 128  # Typical sequence length for character-level models\n",
    "x_int, y_int = make_seqs_and_labels(corpus, char2ind_map, seq_len)\n",
    "\n",
    "# Create validation and training splits according to the requirements\n",
    "# For the validation set, use the 1st 200 sequences\n",
    "x_val = x_int[:200]\n",
    "y_val = y_int[:200]\n",
    "\n",
    "# For the training set, use all sequences beyond the 1st 200\n",
    "x_train = x_int[200:]\n",
    "y_train = y_int[200:]\n",
    "\n",
    "# Define the padding character (this is used for the GPTMini6 model)\n",
    "padding_char_enc = char2ind_map['#']\n",
    "\n",
    "# Initialize the GPTMini6 model with default hyperparameters\n",
    "model = GPTMini6(\n",
    "    vocab_sz=len(vocab),\n",
    "    seq_len=seq_len,\n",
    "    padding_char_enc=padding_char_enc,\n",
    "    num_heads=6,\n",
    "    embed_dim=384,\n",
    "    dropout_rate=0.2\n",
    ")\n",
    "\n",
    "# Compile the model with cross entropy loss and Adam optimizer\n",
    "model.compile(loss='temporal_cross_entropy', optimizer='adam', lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e845cdba",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1747061153.945329     718 service.cc:145] XLA service 0x70a63417a690 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1747061153.945366     718 service.cc:153]   StreamExecutor device (0): NVIDIA L4, Compute Capability 8.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 14:45:54.217587: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 14:45:54.715622: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 90400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1747061155.151239     718 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: Train Loss: 3.4318, Val Loss: 3.2835, Val Acc: 0.0000, Time: 64.61s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100: Train Loss: 3.0924, Val Loss: 2.6623, Val Acc: 0.0000, Time: 22.75s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100: Train Loss: 2.5985, Val Loss: 2.4346, Val Acc: 0.0000, Time: 22.80s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100: Train Loss: 2.3810, Val Loss: 2.2760, Val Acc: 0.0000, Time: 22.83s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100: Train Loss: 2.2294, Val Loss: 2.1163, Val Acc: 0.0000, Time: 22.86s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100: Train Loss: 2.0856, Val Loss: 1.9880, Val Acc: 0.0000, Time: 22.91s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100: Train Loss: 1.9469, Val Loss: 1.8761, Val Acc: 0.0000, Time: 22.92s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100: Train Loss: 1.8292, Val Loss: 1.7870, Val Acc: 0.0000, Time: 22.96s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100: Train Loss: 1.7377, Val Loss: 1.7147, Val Acc: 0.0000, Time: 22.96s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100: Train Loss: 1.6600, Val Loss: 1.6369, Val Acc: 0.0000, Time: 22.94s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100: Train Loss: 1.5981, Val Loss: 1.5983, Val Acc: 0.0000, Time: 22.94s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100: Train Loss: 1.5514, Val Loss: 1.5651, Val Acc: 0.0000, Time: 22.92s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100: Train Loss: 1.5109, Val Loss: 1.5412, Val Acc: 0.0000, Time: 22.94s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100: Train Loss: 1.4756, Val Loss: 1.5142, Val Acc: 0.0000, Time: 22.94s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100: Train Loss: 1.4431, Val Loss: 1.5015, Val Acc: 0.0000, Time: 22.93s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100: Train Loss: 1.4176, Val Loss: 1.4829, Val Acc: 0.0000, Time: 22.92s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100: Train Loss: 1.3936, Val Loss: 1.4836, Val Acc: 0.0000, Time: 22.94s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100: Train Loss: 1.3698, Val Loss: 1.4639, Val Acc: 0.0000, Time: 22.95s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100: Train Loss: 1.3507, Val Loss: 1.4531, Val Acc: 0.0000, Time: 22.96s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100: Train Loss: 1.3304, Val Loss: 1.4542, Val Acc: 0.0000, Time: 22.95s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100: Train Loss: 1.3162, Val Loss: 1.4487, Val Acc: 0.0000, Time: 22.92s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100: Train Loss: 1.2966, Val Loss: 1.4427, Val Acc: 0.0000, Time: 22.92s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100: Train Loss: 1.2816, Val Loss: 1.4323, Val Acc: 0.0000, Time: 22.94s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100: Train Loss: 1.2660, Val Loss: 1.4395, Val Acc: 0.0000, Time: 22.95s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100: Train Loss: 1.2529, Val Loss: 1.4435, Val Acc: 0.0000, Time: 22.92s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100: Train Loss: 1.2374, Val Loss: 1.4457, Val Acc: 0.0000, Time: 22.92s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100: Train Loss: 1.2209, Val Loss: 1.4516, Val Acc: 0.0000, Time: 22.93s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100: Train Loss: 1.2073, Val Loss: 1.4466, Val Acc: 0.0000, Time: 22.93s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/100: Train Loss: 1.1968, Val Loss: 1.4599, Val Acc: 0.0000, Time: 22.93s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100: Train Loss: 1.1841, Val Loss: 1.4617, Val Acc: 0.0000, Time: 22.95s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100: Train Loss: 1.1685, Val Loss: 1.4625, Val Acc: 0.0000, Time: 22.93s\n",
      "Current lr= 0.001 Updated lr= 0.0005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100: Train Loss: 1.1276, Val Loss: 1.4600, Val Acc: 0.0000, Time: 22.93s\n",
      "Current lr= 0.0005 Updated lr= 0.00025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100: Train Loss: 1.0962, Val Loss: 1.4566, Val Acc: 0.0000, Time: 22.94s\n",
      "Current lr= 0.00025 Updated lr= 0.000125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/100: Train Loss: 1.0752, Val Loss: 1.4599, Val Acc: 0.0000, Time: 22.93s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/100: Train Loss: 1.0668, Val Loss: 1.4608, Val Acc: 0.0000, Time: 22.94s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100: Train Loss: 1.0630, Val Loss: 1.4671, Val Acc: 0.0000, Time: 22.94s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/100: Train Loss: 1.0594, Val Loss: 1.4737, Val Acc: 0.0000, Time: 22.94s\n",
      "Finished training after 37 epochs!\n"
     ]
    }
   ],
   "source": [
    "train_loss_hist, val_loss_hist, val_acc_hist, n_epochs = model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    x_val=x_val,\n",
    "    y_val=y_val,\n",
    "    batch_size=64,\n",
    "    max_epochs=100,\n",
    "    patience=15,\n",
    "    lr_patience=9,\n",
    "    lr_decay_factor=0.5,\n",
    "    lr_max_decays=3,\n",
    "    val_every=1,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0bf1f9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 9c. Prompt GPT to generate Shakespearian text  \n",
    "\n",
    "Have your GPT to generate a large amount of text (e.g. generate 5000 chars) that follows a prompt of your choice (a string containing few words or a sentence).\n",
    "\n",
    "**Guidelines**\n",
    "1. Use your `make_ind2char_mapping` from the math datasets to make the reverse map.\n",
    "2. Use the `'distributed'` method for generating text.\n",
    "\n",
    "When you turn in your project, include an example of at least one long passage of generated text by your GPT below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ad8bb759",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from addition_dataset import make_ind2char_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "80384f47",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: To be, or not to be: that is the question:\n",
      "To be, or not to be: that is the question:\n",
      "I"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " wi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ll "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " st"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ay "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e a"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gai"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PE"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRU"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHI"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wha"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t, "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hol"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d, "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lor"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KA"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THA"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RIN"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I t"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "han"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k t"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hee"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", t"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hou"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gh "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I d"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "say"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " it"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " is"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " no"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PE"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRU"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHI"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wel"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l, "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lor"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KA"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THA"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RIN"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I w"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ill"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " be"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " so"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " fa"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lse"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " of"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " th"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ea "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "of "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " se"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " th"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ere"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e I"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " wi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ll "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "olv"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e y"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ou "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " no"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t a"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " wo"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rd."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "P"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETR"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UCH"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IO:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "We"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ll,"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " my"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " lo"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rd."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATH"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARI"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NA:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wou"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ld "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ha"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ve "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hea"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rd "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " se"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nat"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ors"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " of"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " th"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ea,"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "An"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d t"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efo"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "re "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I w"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ill"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " re"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sol"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ve "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " wi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "th "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "me."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "P"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETR"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UCH"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IO:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "We"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ll,"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " my"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " lo"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rd."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATH"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARI"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NA:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wou"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ld "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ha"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ve "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hea"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rd "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "him"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " fr"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "om "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "son"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PET"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUC"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HIO"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":\n",
      "W"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ell"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y l"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ord"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KAT"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HAR"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INA"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":\n",
      "I"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " wo"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uld"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " no"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ave"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " he"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ard"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " th"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ena"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tor"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " se"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nat"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ors"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " of"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " th"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ea "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "of "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " se"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " th"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ere"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e I"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " wi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ll "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "olv"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e y"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ou "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wit"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "im."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "P"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETR"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UCH"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IO:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "We"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ll,"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " my"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " lo"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rd."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATH"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARI"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NA:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wou"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ld "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ha"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ve "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hea"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rd "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " se"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nat"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ors"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " of"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " th"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ea,"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "An"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d t"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efo"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "re "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I w"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ill"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " re"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sol"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ve "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " wi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "th "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "me."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "P"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETR"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UCH"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IO:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "We"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ll,"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " my"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " lo"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rd."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATH"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARI"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NA:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wou"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ld "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ha"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ve "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hea"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rd "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "him"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " fr"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "om "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "son"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PET"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUC"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HIO"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":\n",
      "W"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ell"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y l"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ord"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KAT"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HAR"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INA"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":\n",
      "I"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " wo"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uld"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " no"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ave"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " he"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ard"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " th"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ena"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tor"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " se"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nat"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ors"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " of"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " th"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ea "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "of "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " se"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " th"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ere"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e I"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " wi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ll "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "olv"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e y"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ou "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wit"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "im."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "P"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETR"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UCH"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IO:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "We"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ll,"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " my"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " lo"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rd."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATH"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARI"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NA:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wou"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ld "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ha"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ve "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hea"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rd "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " se"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nat"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ors"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " of"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " th"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ea,"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "An"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d t"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efo"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "re "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I w"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ill"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " re"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sol"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ve "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " wi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "th "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "me."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "P"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETR"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UCH"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IO:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "We"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ll,"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " my"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " lo"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rd."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATH"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARI"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NA:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wou"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ld "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ha"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ve "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hea"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrompt: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprompt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m model\u001b[38;5;241m.\u001b[39mseq_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m128\u001b[39m\n\u001b[0;32m----> 7\u001b[0m gen_text \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_sequence\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlength\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Generate 5000 characters\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchar2ind_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchar2ind_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mind2char_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mind2char_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlive_print\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Print the final generated text\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m***final output***\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/proj 4/gpts.py:191\u001b[0m, in \u001b[0;36mGPT.generate_sequence\u001b[0;34m(self, prompt, length, char2ind_map, ind2char_map, end_char, method, plot_probs, live_print)\u001b[0m\n\u001b[1;32m    189\u001b[0m x_input_tf \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mexpand_dims(context, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# N, T\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# Get net_acts from output layer\u001b[39;00m\n\u001b[0;32m--> 191\u001b[0m out_net_act \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_input_tf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;66;03m# Important: Squeeze / convert to numpy before drawing from softmax dist.\u001b[39;00m\n\u001b[1;32m    194\u001b[0m out_probs_np \u001b[38;5;241m=\u001b[39m out_net_act[\u001b[38;5;241m0\u001b[39m, t_ind]\u001b[38;5;241m.\u001b[39mnumpy()  \u001b[38;5;66;03m# probs from only last time step\u001b[39;00m\n",
      "File \u001b[0;32m~/proj 4/gpts.py:122\u001b[0m, in \u001b[0;36mGPT.__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    120\u001b[0m net_act \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cur_layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m--> 122\u001b[0m     net_act \u001b[38;5;241m=\u001b[39m \u001b[43mcur_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet_act\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m net_act\n",
      "File \u001b[0;32m~/proj 4/transformer_blocks.py:442\u001b[0m, in \u001b[0;36mTransformerBlock.__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    436\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m attn_output  \u001b[38;5;66;03m# Residual connection\u001b[39;00m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;66;03m# second normalization layer \u001b[39;00m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;66;03m# norm2 = self.ln2(attn_output)\u001b[39;00m\n\u001b[1;32m    440\u001b[0m \n\u001b[1;32m    441\u001b[0m \u001b[38;5;66;03m# MLP with residual connection\u001b[39;00m\n\u001b[0;32m--> 442\u001b[0m mlp_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m output \u001b[38;5;241m=\u001b[39m attn_output \u001b[38;5;241m+\u001b[39m mlp_output  \u001b[38;5;66;03m# Residual connection\u001b[39;00m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/proj 4/transformer_blocks.py:358\u001b[0m, in \u001b[0;36mMLPBlock.__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''Forward pass through the MLPBlock with the data samples `x`.\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \n\u001b[1;32m    347\u001b[0m \u001b[38;5;124;03mParameters:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[38;5;124;03m    The output netActs\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;66;03m# pass through first dense layer\u001b[39;00m\n\u001b[0;32m--> 358\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;66;03m# pass through second dense layer\u001b[39;00m\n\u001b[1;32m    361\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense2(x)\n",
      "File \u001b[0;32m~/proj 4/layers.py:212\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_gain \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_layernorm_params(x)\n\u001b[0;32m--> 212\u001b[0m     x \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_layer_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    213\u001b[0m net_in \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_net_input(x)\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_batch_norm \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "File \u001b[0;32m~/proj 4/layers.py:400\u001b[0m, in \u001b[0;36mLayer.compute_layer_norm\u001b[0;34m(self, x, eps)\u001b[0m\n\u001b[1;32m    396\u001b[0m std_i \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39msqrt(tf\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mreduce_variance(x, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[1;32m    398\u001b[0m x_norm \u001b[38;5;241m=\u001b[39m (x \u001b[38;5;241m-\u001b[39m mean_i) \u001b[38;5;241m/\u001b[39m (std_i \u001b[38;5;241m+\u001b[39m eps)\n\u001b[0;32m--> 400\u001b[0m x_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln_gain\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx_norm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln_bias\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x_out\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/override_binary_operator.py:113\u001b[0m, in \u001b[0;36moverride_binary_operator_helper.<locals>.binary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    109\u001b[0m   \u001b[38;5;66;03m# force_same_dtype=False to preserve existing TF behavior\u001b[39;00m\n\u001b[1;32m    110\u001b[0m   \u001b[38;5;66;03m# TODO(b/178860388): Figure out why binary_op_wrapper and\u001b[39;00m\n\u001b[1;32m    111\u001b[0m   \u001b[38;5;66;03m#   r_binary_op_wrapper use different force_same_dtype values.\u001b[39;00m\n\u001b[1;32m    112\u001b[0m   x, y \u001b[38;5;241m=\u001b[39m maybe_promote_tensors(x, y)\n\u001b[0;32m--> 113\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    115\u001b[0m   \u001b[38;5;66;03m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[39;00m\n\u001b[1;32m    116\u001b[0m   \u001b[38;5;66;03m# object that can implement the operator with knowledge of itself\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    119\u001b[0m   \u001b[38;5;66;03m# original error from the LHS, because it may be more\u001b[39;00m\n\u001b[1;32m    120\u001b[0m   \u001b[38;5;66;03m# informative.\u001b[39;00m\n\u001b[1;32m    121\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mtype\u001b[39m(y), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__r\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m__\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m op_name):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/tensor_math_operator_overrides.py:28\u001b[0m, in \u001b[0;36m_add_dispatch_factory\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_add_dispatch_factory\u001b[39m(x, y, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     26\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m math_ops\n\u001b[0;32m---> 28\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmath_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_add_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1260\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1262\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1264\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/math_ops.py:1691\u001b[0m, in \u001b[0;36m_add_dispatch\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1688\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m add(x, y, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[1;32m   1689\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(y, tensor_lib\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m   1690\u001b[0m     y, sparse_tensor\u001b[38;5;241m.\u001b[39mSparseTensor):\n\u001b[0;32m-> 1691\u001b[0m   y \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype_hint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1692\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mstring:\n\u001b[1;32m   1693\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m gen_math_ops\u001b[38;5;241m.\u001b[39madd(x, y, name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/profiler/trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m Trace(trace_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrace_kwargs):\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py:713\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[38;5;66;03m# TODO(b/142518781): Fix all call-sites and remove redundant arg\u001b[39;00m\n\u001b[1;32m    712\u001b[0m preferred_dtype \u001b[38;5;241m=\u001b[39m preferred_dtype \u001b[38;5;129;01mor\u001b[39;00m dtype_hint\n\u001b[0;32m--> 713\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor_conversion_registry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreferred_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccepted_result_types\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/tensor_conversion_registry.py:224\u001b[0m, in \u001b[0;36mconvert\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    222\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m--> 224\u001b[0m         \u001b[43mret\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_dtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpreferred_dtype\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_dtype\u001b[49m):\n\u001b[1;32m    225\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    226\u001b[0m           _add_error_prefix(\n\u001b[1;32m    227\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconversion_func\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m for type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactual = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mret\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase_dtype\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    231\u001b[0m               name\u001b[38;5;241m=\u001b[39mname))\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/dtypes.py:279\u001b[0m, in \u001b[0;36mDType.__ne__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__ne__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m    278\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns True iff self != other.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 279\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__eq__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/dtypes.py:266\u001b[0m, in \u001b[0;36mDType.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m    265\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns True iff this DType refers to the same type as `other`.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m other \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    269\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(other) \u001b[38;5;241m!=\u001b[39m DType:  \u001b[38;5;66;03m# pylint: disable=unidiomatic-typecheck\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ind2char_map = make_ind2char_mapping(char2ind_map)\n",
    "\n",
    "prompt = \"To be, or not to be: that is the question:\"\n",
    "print(f\"Prompt: {prompt}\")\n",
    "\n",
    "model.seq_len = 128\n",
    "gen_text = model.generate_sequence(\n",
    "    prompt=prompt,\n",
    "    length=5000,  # Generate 5000 characters\n",
    "    char2ind_map=char2ind_map,\n",
    "    ind2char_map=ind2char_map,\n",
    "    method='max',\n",
    "    live_print=True,\n",
    ")\n",
    "\n",
    "# Print the final generated text\n",
    "print('***final output***')\n",
    "print(prompt + ''.join(gen_text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2c7c5a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 9d. Questions\n",
    "\n",
    "**Question 9:** Rerun your generation using the `'max'` method. Which method generates better sounding/more interesting text? **Why?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94714d5f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Answer 9:**\n",
    "The distributed method sounds much better, and this is due to the creative nature of it. By not selecting the top predicted char in the softmax output each time, the text varies. However, run running with 'max', the model falls into a cycle pattern where it repeats the same few lines, due to the only selecting the chars with the highest softmax output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3523a5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Extensions\n",
    "\n",
    "### General guidelines\n",
    "\n",
    "1. Never integrate extensions into your base project so that they change the expected behavior of core functions. If your extension changes the core design/behavior, no problem, duplicate your working base project and add features from there.\n",
    "2. Check the rubric to keep in mind how extensions on this project will be graded.\n",
    "3. While I may consult your code and \"written log\" of what you did, **I am grading your extensions based on what you present in your 3-5 min video.**\n",
    "3. I suggest documenting your explorations in a \"log\" or \"lab notebook\" style (i.e. documenting your thought/progression/discovery/learning process). I'm not grading your writing, so you can keep it succinct. **Whatever is most useful to you to remember what you did.** \n",
    "4. I suggest taking a hypothesis driven approach. For example \"I was curious about X so I explored Y. I found Z, which was not what I expected because..., so then tried A...\"\n",
    "5. Make plots to help showcase your results.\n",
    "6. **More is not necessarily better.** Generally, a small number of \"in-depth\" extensions count for more than many \"shallow\" extensions.\n",
    "\n",
    "### AI guidelines\n",
    "\n",
    "You may use AI in mostly any capacity for extensions. However, keep in mind:\n",
    "1. There is no need to use AI at all!\n",
    "2. You are welcome to use AI as a tool (e.g. automate something that is tedious, help you get unstuck, etc.). However, you should be coding, you should be thinking, you should be writing, you should be creating. If you are spending most (or even close to most) of your time typing into a chatbot and copy-pasting, you have probably gone too far with AI use.\n",
    "3. I don't find large volumes of AI generated code/text/plots to be particularly impressive and you risk losing my interest while grading. Remember: I'm grading your extensions based on your video presentation. **More is not necessarily better.**\n",
    "\n",
    "### Video guidelines\n",
    "\n",
    "1. Please try to keep your video to 5 minutes (*I have other projects to grade!*). If you turn in a longer video, I make no promise that I will watch more than 5 minutes.\n",
    "2. Your screen should be shared as you show me what you did. A live video of your face should also appear somewhere on the screen (e.g. picture-in-picture overlay / split screen).\n",
    "3. Your partner should join you for the video and take turns talking, but, if necessary, it is fine to have one team member present during the record the video.\n",
    "4. Do not simply read text from your notebook, do not read from a prepared script. I am not grading how polished your video presentation is (see extension grading criteria on rubric). \n",
    "5. I am looking for original and creative explorations sparked by your curiosity/interest/passion in a topic. This should be apparent in your video.\n",
    "6. Be natural,, don't feel the need to impress me with fancy language. If it is helpful, imagine that we are talking one-on-one about your extension. Tell me what you did :)\n",
    "\n",
    "### Extension ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec837871",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 1. Generate text based on other corpora\n",
    "\n",
    "Train one of your GPTs on a different text dataset and use it to generate text that resembles that body of work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ab216c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 2. GPT-1\n",
    "\n",
    "Train OpenAI's GPT-1 model. It has the same architecture as `GPTMini6` except it has:\n",
    "- 12 stacked Transformer Blocks\n",
    "- 12 attention heads\n",
    "- Embedding dimension of 768\n",
    "- Dropout rate of 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6310e422",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 3. GPT-2\n",
    "\n",
    "Train a model in the family of OpenAI's GPT2 models. It has the same architecture as `GPTMini6` except it has different values for (number of transformer blocks, embedding dimension, attention heads):\n",
    "\n",
    "**GPT-2 Medium:** (24, 1024, 16)<br/>\n",
    "**GPT-2 Large:** (36, 1280, 20)<br/>\n",
    "**GPT-2 XL:** (48, 1600, 25)\n",
    "\n",
    "Feel free to adapt/pare down based on training time and GPU resources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654b1009",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 4. More complex arithmetic\n",
    "\n",
    "Explore any of the following:\n",
    "- Train your transformers to perform addition and/or multiplication with larger numbers.\n",
    "- Add support for negative integer operands.\n",
    "- Allow for longer chains of operands (e.g. `1+1+1+1=4`)\n",
    "- Add support for subtraction and/or other arithmetic operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e529e9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 5. Explore hyperparameters\n",
    "\n",
    "Explore how any of the following affects the quality of the generated text and/or loss:\n",
    "- Sequence length\n",
    "- Embedding dimension"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "/usr/bin/python3",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3.10.12",
   "env": {
   },
   "language": "python",
   "metadata": {
    "debugger": true
   },
   "name": "python3",
   "resource_dir": "/usr/local/share/jupyter/kernels/python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}