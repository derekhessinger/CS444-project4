{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "648d72",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**YOUR NAMES HERE**\n",
    "\n",
    "Spring 2025\n",
    "\n",
    "CS 444: Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "63092d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of transformer_layers failed: Traceback (most recent call last):\n",
      "  File \"c:\\Users\\AlexL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 261, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"c:\\Users\\AlexL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 484, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"c:\\Users\\AlexL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 381, in update_generic\n",
      "    update(a, b)\n",
      "  File \"c:\\Users\\AlexL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 333, in update_class\n",
      "    if update_generic(old_obj, new_obj):\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\AlexL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 381, in update_generic\n",
      "    update(a, b)\n",
      "  File \"c:\\Users\\AlexL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 293, in update_function\n",
      "    setattr(old, name, getattr(new, name))\n",
      "ValueError: __init__() requires a code object with 0 free vars, not 2546915606529\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(['seaborn-v0_8-colorblind', 'seaborn-v0_8-darkgrid'])\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "\n",
    "np.set_printoptions(suppress=True, precision=4)\n",
    "\n",
    "# Automatically reload your external source code\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29da6d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Project 4 | Transformers\n",
    "\n",
    "The focus of this project is on the **Transformer neural network architecture**, which was introduced in the (now famous) paper *Attention is All you Need* by [Vaswani et al. (2017)](https://arxiv.org/abs/1706.03762). This neural network architecture is THE foundation of all modern large language models (e.g. OpenAI's GPT line of models, Anthropic Claude, Google Gemini, Meta Llama, DeepSeek, etc.). You will implement and train transformer networks on large amounts of text data. The transformer networks in this project adhere to the general structure of OpenAI's **Generative Pretrained Transformer (GPT)** models.\n",
    "\n",
    "Once you build on your deep learning library to support the transformer architecture in this notebook, you will train small transformers to add and multiply numbers (i.e. evaluate strings of arithmetic operations, such as `'1+1='`). The last part of the project focuses on training larger transformers on a large text corpus — the entire works of William Shakespeare. When you prompt your transformers with some starter text, they will generate novel text that follows your prompt and generally resembles the text used to train the network (e.g. a Shakespearian play).\n",
    "\n",
    "<!-- #### Week 1: Build a transformer neural network -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e24db",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![Some fun](images/transformer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71d9e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Task 1: Generate the addition dataset\n",
    "\n",
    "In this task, you will write code to generate and preprocess a dataset composed of strings that represent arithmetic addition expressions involving up to 2 digit non-negative integer operands. For example, `'20+30=50'` and `'2+30=32'`are allowed, but not `'300+5=305'`. You will train a transformer on a large numbers of such expressions then you will prompt it to generate the answer to the right of the equals sign. For example, once trained you could prompt the transformer with `'21+23='` and it should return `'44'`.\n",
    "\n",
    "#### Data format\n",
    "\n",
    "In this project, we will be working with text data and we are implementing a **character-level model** (unlike the word-level model used in the Word Embedding project). This means that each data sample is a sequence of `T` characters (i.e. tokens), which, for example, could be a part of a sentence or the characters that make up an arithmetic expression. So all the data samples in the dataset will have shape `(N, T)`. Just like in the Word Embedding project, we int-code each char/token in the dataset based on the character's position in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e91d59",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from addition_dataset import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27455",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1a. Verify `make_addition_expressions` outputs\n",
    "\n",
    "In the cell below, use the provided `make_addition_expressions` to generate 25,000 addition expressions involving at most 2 digit operands (i.e. maximum operand of `99`). Use the default random seed. Assign the list of addition expressions to a variable called `addition_ds` and the vocabulary dictionary to a variable called `char2ind_map`.\n",
    "\n",
    "When executed, the function should print:\n",
    "\n",
    "```\n",
    "First 5/25000 expressions:\n",
    "  ['4', '7', '+', '5', '1', '=', '9', '8', '.', '#']\n",
    "  ['7', '5', '+', '9', '5', '=', '1', '7', '0', '.']\n",
    "  ['3', '+', '1', '4', '=', '1', '7', '.', '#', '#']\n",
    "  ['8', '2', '+', '9', '4', '=', '1', '7', '6', '.']\n",
    "  ['2', '4', '+', '3', '1', '=', '5', '5', '.', '#']\n",
    "```\n",
    "\n",
    "#### Token encoding\n",
    "\n",
    "To aid in interpretability of the int-coded tokens, we will represent the each `0-9` digit of the integer operands being summed as `0-9` in the int coding. We map the following chars to the next available ints in our coding scheme:\n",
    "- `'+'` → 10\n",
    "- `'='` → 11\n",
    "\n",
    "We introduce a \"fake\" token `'.'` (int code: 12) within our vocabulary, our data samples, and our labels, which indicates the end of each addition expression (**end token**). For example `'47+51=98.'`. This helps the transformer know when the last \"real\" token/char in each addition expression has been reached (i.e. there are no more numbers to the right) and when it generates text after training, the transformer can output the int code corresponding `'.'` to signify that it is done generating text.\n",
    "\n",
    "We introduce another \"fake\" token `'#'` (int code: 13), which we call the **padding token**. Our transformers must be trained on fixed-length sequences, but different addition expressions have different length (i.e. the length of `'1+1=2'` is shorter than `'1+9=10'`). To overcome this issue with samples in our dataset, we use the padding token to right-pad any expression that has fewer characters than our longest supported expression `'99+99=198'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "43d30b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5/25000 expressions:\n",
      "  ['4', '7', '+', '5', '1', '=', '9', '8', '.', '#']\n",
      "  ['7', '5', '+', '9', '5', '=', '1', '7', '0', '.']\n",
      "  ['3', '+', '1', '4', '=', '1', '7', '.', '#', '#']\n",
      "  ['8', '2', '+', '9', '4', '=', '1', '7', '6', '.']\n",
      "  ['2', '4', '+', '3', '1', '=', '5', '5', '.', '#']\n"
     ]
    }
   ],
   "source": [
    "addition_ds, char2ind_map = make_addition_expressions(25000, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165a9b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1b. Create addition int-coded dataset samples and labels\n",
    "\n",
    "To do this we must\n",
    "- convert each char in each addition expression into an int-code (*using the vocabulary*).\n",
    "- define the \"class labels\" or the characters we want the transformer to predict at each time step. This is simply the int code of next character in each the expression to the right of the current one. For example, for `'9+2=11'` the first token in the data sample is `9` and the first class label is `10` (the int code for `'+'`).\n",
    "\n",
    "Implement `make_addition_samples_and_labels` in `addition_dataset.py` to perform the above tasks then test your code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e50d0a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few samples (encoded):\n",
      "[4, 7, 10, 5, 1, 11, 9, 8, 12]\n",
      "[7, 5, 10, 9, 5, 11, 1, 7, 0]\n",
      "[3, 10, 1, 4, 11, 1, 7, 12, 13]\n",
      "[8, 2, 10, 9, 4, 11, 1, 7, 6]\n",
      "[2, 4, 10, 3, 1, 11, 5, 5, 12]\n",
      "First few labels (encoded):\n",
      "[7, 10, 5, 1, 11, 9, 8, 12, 13]\n",
      "[5, 10, 9, 5, 11, 1, 7, 0, 12]\n",
      "[10, 1, 4, 11, 1, 7, 12, 13, 13]\n",
      "[2, 10, 9, 4, 11, 1, 7, 6, 12]\n",
      "[4, 10, 3, 1, 11, 5, 5, 12, 13]\n"
     ]
    }
   ],
   "source": [
    "x_int_test, y_int_test = make_addition_samples_and_labels(addition_ds, char2ind_map)\n",
    "\n",
    "print('First few samples (encoded):')\n",
    "for i in range(5):\n",
    "    print(x_int_test[i])\n",
    "print('First few labels (encoded):')\n",
    "for i in range(5):\n",
    "    print(y_int_test[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45862b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The above should print:\n",
    "\n",
    "```\n",
    "First few samples (encoded):\n",
    "[4, 7, 10, 5, 1, 11, 9, 8, 12]\n",
    "[7, 5, 10, 9, 5, 11, 1, 7, 0]\n",
    "[3, 10, 1, 4, 11, 1, 7, 12, 13]\n",
    "[8, 2, 10, 9, 4, 11, 1, 7, 6]\n",
    "[2, 4, 10, 3, 1, 11, 5, 5, 12]\n",
    "First few labels (encoded):\n",
    "[7, 10, 5, 1, 11, 9, 8, 12, 13]\n",
    "[5, 10, 9, 5, 11, 1, 7, 0, 12]\n",
    "[10, 1, 4, 11, 1, 7, 12, 13, 13]\n",
    "[2, 10, 9, 4, 11, 1, 7, 6, 12]\n",
    "[4, 10, 3, 1, 11, 5, 5, 12, 13]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24de66",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1c. Create dictionary converting int-coded tokens back into chars\n",
    "\n",
    "Your transformer will output ints — the int-coded representation of the predicted next char. For example, if the transformer outputs `'11'` that should be converted to `'='` for interpretability. \n",
    "\n",
    "Implement and test `make_ind2char_mapping` in `addition_dataset.py` to create the dictionary that will use the vocabulary to map int-coded representations of tokens back to chars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "834d71",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is your ind2char_map:\n",
      "{0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9', 10: '+', 11: '=', 12: '.', 13: '#'}\n",
      "it should be\n",
      "{0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9', 10: '+', 11: '=', 12: '.', 13: '#'}\n",
      "Here is your char2ind_map:\n",
      "{'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9, '+': 10, '=': 11, '.': 12, '#': 13}\n",
      "it should be\n",
      "{'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9, '+': 10, '=': 11, '.': 12, '#': 13}\n"
     ]
    }
   ],
   "source": [
    "ind2char_map = make_ind2char_mapping(char2ind_map)\n",
    "\n",
    "print(f'Here is your ind2char_map:\\n{ind2char_map}\\nit should be')\n",
    "print(\"{0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9', 10: '+', 11: '=', 12: '.', 13: '#'}\")\n",
    "print(f'Here is your char2ind_map:\\n{char2ind_map}\\nit should be')\n",
    "print(\"{'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9, '+': 10, '=': 11, '.': 12, '#': 13}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9c30",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1d. Convert from int-coded tokens back to characters\n",
    "\n",
    "Because you will prompt your transformer with string input (like a chatbot) and we would like to make sense of the transformer predictions, let's write a function (`convert_int2str`) that automates the process of taking int-coded samples back into human-readable characters then test it below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "915fe0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few samples converted back to chars:\n",
      "['4', '7', '+', '5', '1', '=', '9', '8', '.']\n",
      "['7', '5', '+', '9', '5', '=', '1', '7', '0']\n",
      "['3', '+', '1', '4', '=', '1', '7', '.', '#']\n",
      "['8', '2', '+', '9', '4', '=', '1', '7', '6']\n",
      "['2', '4', '+', '3', '1', '=', '5', '5', '.']\n",
      "First few labels converted back to chars:\n",
      "['7', '+', '5', '1', '=', '9', '8', '.', '#']\n",
      "['5', '+', '9', '5', '=', '1', '7', '0', '.']\n",
      "['+', '1', '4', '=', '1', '7', '.', '#', '#']\n",
      "['2', '+', '9', '4', '=', '1', '7', '6', '.']\n",
      "['4', '+', '3', '1', '=', '5', '5', '.', '#']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_str_test = convert_int2str(x_int_test, ind2char_map)\n",
    "y_str_test = convert_int2str(y_int_test, ind2char_map)\n",
    "\n",
    "print('First few samples converted back to chars:')\n",
    "for i in range(5):\n",
    "    print(x_str_test[i])\n",
    "print('First few labels converted back to chars:')\n",
    "for i in range(5):\n",
    "    print(y_str_test[i])\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4adc1",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The above cell should output:\n",
    "\n",
    "```\n",
    "First few samples:\n",
    "['4', '7', '+', '5', '1', '=', '9', '8', '.']\n",
    "['7', '5', '+', '9', '5', '=', '1', '7', '0']\n",
    "['3', '+', '1', '4', '=', '1', '7', '.', '#']\n",
    "['8', '2', '+', '9', '4', '=', '1', '7', '6']\n",
    "['2', '4', '+', '3', '1', '=', '5', '5', '.']\n",
    "First few labels:\n",
    "['7', '+', '5', '1', '=', '9', '8', '.', '#']\n",
    "['5', '+', '9', '5', '=', '1', '7', '0', '.']\n",
    "['+', '1', '4', '=', '1', '7', '.', '#', '#']\n",
    "['2', '+', '9', '4', '=', '1', '7', '6', '.']\n",
    "['4', '+', '3', '1', '=', '5', '5', '.', '#']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa30b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1e. Create train-validation split\n",
    "\n",
    "Implement `make_train_val_split` in `addition_dataset.py` to divide the dataset into training and validation split then run the code below to check your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2ac5de",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training samples shape is: (22500, 9) and should be (22500, 9).\n",
      "The training labels shape is: (22500, 9) and should be (22500, 9).\n",
      "The validation samples shape is: (2500, 9) and should be (2500, 9).\n",
      "The validation labels shape is: (2500, 9) and should be (2500, 9).\n"
     ]
    }
   ],
   "source": [
    "x_train_test, y_train_test, x_val_test, y_val_test = make_train_val_split(x_int_test, y_int_test)\n",
    "\n",
    "print(f'The training samples shape is: {x_train_test.shape} and should be (22500, 9).')\n",
    "print(f'The training labels shape is: {y_train_test.shape} and should be (22500, 9).')\n",
    "print(f'The validation samples shape is: {x_val_test.shape} and should be (2500, 9).')\n",
    "print(f'The validation labels shape is: {y_val_test.shape} and should be (2500, 9).')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad629f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1f. Create addition dataset prompts and expected output\n",
    "\n",
    "After training the transformer on expressions such as `'1+1=2.####'`, you will prompt it with `1+1=` and we expect it to generate `'2.'` (the `'.'` indicates it is done generating text). Let's write the `split_sum_and_answer` function to automate the process of generating the prompts and expected outputs for samples in either the train or validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "cd3575",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First five training prompts and answers:\n",
      "prompt: 47+51= | answer: 98.\n",
      "prompt: 75+95= | answer: 170\n",
      "prompt: 3+14= | answer: 17.#\n",
      "prompt: 82+94= | answer: 176\n",
      "prompt: 24+31= | answer: 55.\n"
     ]
    }
   ],
   "source": [
    "lhs_lists, ans_lists = split_sum_and_answer(x_str_test)\n",
    "\n",
    "print('First five training prompts and answers:')\n",
    "for i in range(5):\n",
    "    print(f'prompt: {lhs_lists[i]} | answer: {ans_lists[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b9bf",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The above cell should output:\n",
    "\n",
    "```\n",
    "First five training prompts and answers:\n",
    "prompt: 47+51= | answer: 98.\n",
    "prompt: 75+95= | answer: 170\n",
    "prompt: 3+14= | answer: 17.#\n",
    "prompt: 82+94= | answer: 176\n",
    "prompt: 24+31= | answer: 55.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a54d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1g. Automate addition dataset preprocessing\n",
    "\n",
    "Call the functions that you wrote to get and preprocess the addition dataset all in one function called `get_addition_dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "48d918",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5/100 expressions:\n",
      "  ['4', '7', '+', '5', '1', '=', '9', '8', '.', '#']\n",
      "  ['7', '5', '+', '9', '5', '=', '1', '7', '0', '.']\n",
      "  ['3', '+', '1', '4', '=', '1', '7', '.', '#', '#']\n",
      "  ['8', '2', '+', '9', '4', '=', '1', '7', '6', '.']\n",
      "  ['2', '4', '+', '3', '1', '=', '5', '5', '.', '#']\n",
      "The shape of your training samples is (90, 9) and it should be (90, 9).\n",
      "The shape of your training labels is (90, 9) and it should be (90, 9).\n",
      "The shape of your val samples is (10, 9) and it should be (10, 9).\n",
      "The shape of your val labels is (10, 9) and it should be (10, 9).\n"
     ]
    }
   ],
   "source": [
    "x_train_test, y_train_test, x_val_test, y_val_test, char2ind_map_test = get_addition_dataset(N=100)\n",
    "print(f'The shape of your training samples is {x_train_test.shape} and it should be (90, 9).')\n",
    "print(f'The shape of your training labels is {y_train_test.shape} and it should be (90, 9).')\n",
    "print(f'The shape of your val samples is {x_val_test.shape} and it should be (10, 9).')\n",
    "print(f'The shape of your val labels is {y_val_test.shape} and it should be (10, 9).')\n",
    "\n",
    "# We need int coded everything! i.e. tf.int32s\n",
    "assert x_train_test.dtype == tf.int32\n",
    "assert y_train_test.dtype == tf.int32\n",
    "assert x_val_test.dtype == tf.int32\n",
    "assert y_val_test.dtype == tf.int32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68835a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Task 2. Transformer Embedding layer\n",
    "\n",
    "With the addition dataset ready, let's start implementing the transformer!\n",
    "\n",
    "As with CBOW, we use an embedding layer to allow us to select the \"y weights\" that have indices equal to those in our current mini-batch of ints (*e.g. the int-coded addition expressions*). There are two slight changes in the transformer embedding layer compared to the `DenseEmbedding` we used in CBOW:\n",
    "1. We will \"turn off\"/disable the bias.\n",
    "2. We do not need the special casing in `compute_net_input` to handle the lazy initialization. Simply initialize the weights from within the constructor because we know both the number of input features and the number of units in the layer when building the layer (i.e. there is no lazy initialization in this layer).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "346462",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from transformer_layers import Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8c4c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2a. Copy over deeplib files\n",
    "\n",
    "Copy over your latest versions of `layers.py`, `block.py`, `network.py`, and `tf_util.py` from your previous project to your current working directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd2d9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2b. Implement `Embedding` layer\n",
    "\n",
    "The `Embedding` class is located in `transformer_layers.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5793d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Test: Constructor and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "de6a89",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your weights are:\n",
      "[[ 0.6758  0.1891 -0.1877]\n",
      " [-0.4633 -0.5531  0.2103]\n",
      " [-0.0062  0.5317  0.2695]\n",
      " [ 0.2682 -0.3156 -0.1936]\n",
      " [ 0.3549 -0.3119 -0.4293]]\n",
      "and should be:\n",
      "[[ 0.6758  0.1891 -0.1877]\n",
      " [-0.4633 -0.5531  0.2103]\n",
      " [-0.0062  0.5317  0.2695]\n",
      " [ 0.2682 -0.3156 -0.1936]\n",
      " [ 0.3549 -0.3119 -0.4293]]\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(0)\n",
    "emb = Embedding('EmbeddingLayer', input_dim=5, embed_dim=3)\n",
    "print('Your weights are:')\n",
    "print(emb.get_wts().numpy())\n",
    "print('and should be:')\n",
    "print('''[[ 0.6758  0.1891 -0.1877]\n",
    " [-0.4633 -0.5531  0.2103]\n",
    " [-0.0062  0.5317  0.2695]\n",
    " [ 0.2682 -0.3156 -0.1936]\n",
    " [ 0.3549 -0.3119 -0.4293]]''')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4018b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Test: Layer summary and netAct shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9ce183",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding layer summary:\n",
      "Embedding layer output(EmbeddingLayer) shape: [3, 2, 3]\n",
      "it should be:\n",
      "Embedding layer output(EmbeddingLayer) shape: [3, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "test_minibatch = [[1, 2], [0, 2], [3, 4]]\n",
    "emb(test_minibatch)\n",
    "print('Embedding layer summary:')\n",
    "print(emb)\n",
    "print('it should be:')\n",
    "print('Embedding layer output(EmbeddingLayer) shape: [3, 2, 3]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f63f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Test: Activation values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "8c46b5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the test mini-batch, the netActs are:\n",
      "[[[-0.4633 -0.5531  0.2103]\n",
      "  [-0.0062  0.5317  0.2695]]\n",
      "\n",
      " [[ 0.6758  0.1891 -0.1877]\n",
      "  [-0.0062  0.5317  0.2695]]\n",
      "\n",
      " [[ 0.2682 -0.3156 -0.1936]\n",
      "  [ 0.3549 -0.3119 -0.4293]]]\n",
      "and they should be:\n",
      "[[[-0.4633 -0.5531  0.2103]\n",
      "  [-0.0062  0.5317  0.2695]]\n",
      "\n",
      " [[ 0.6758  0.1891 -0.1877]\n",
      "  [-0.0062  0.5317  0.2695]]\n",
      "\n",
      " [[ 0.2682 -0.3156 -0.1936]\n",
      "  [ 0.3549 -0.3119 -0.4293]]]\n"
     ]
    }
   ],
   "source": [
    "print('For the test mini-batch, the netActs are:')\n",
    "print(emb(test_minibatch).numpy())\n",
    "print('and they should be:')\n",
    "print('''[[[-0.4633 -0.5531  0.2103]\n",
    "  [-0.0062  0.5317  0.2695]]\n",
    "\n",
    " [[ 0.6758  0.1891 -0.1877]\n",
    "  [-0.0062  0.5317  0.2695]]\n",
    "\n",
    " [[ 0.2682 -0.3156 -0.1936]\n",
    "  [ 0.3549 -0.3119 -0.4293]]]''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7afa",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2c. Questions\n",
    "\n",
    "**Question 1:** In the above test code, use minimal jargon to explain what each of the three values in the netAct shape `[3, 2, 3]` mean **and** where they came from."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cf9a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Answer 1:** We have the # of batches, 3... then we have T=2, so how many chars. in each sequence... finally, we chose to have H=3, the embedding dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108894",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Task 3. Implement the Transformer Block\n",
    "\n",
    "Analogous to Inception Net and ResNet, transformers contain a fundamental block called the Transformer Block that is copy-pasted many times sequentially in the network. Since there are fair number of layers within the Transformer Block, we will define several \"helper blocks\" or \"subblocks\" to help us make the organization more manageable. These helper blocks are:\n",
    "1. `QueryKeyValueBlock`: Handles the projection/embedding/mapping of the input signal into the three parallel `Dense` layers that learn the attention queries, keys, and values.\n",
    "2. `AttentionBlock`: Implements the attention mechanism (*involves a Dropout layer that operates on the attention values*).\n",
    "3. `MultiHeadAttentionBlock`: Organizes the sequential processing of input signals through the above two blocks as well as subsequent Dense and Dropout layers: `QueryKeyValueBlock` → `AttentionBlock` → `Dense` layer → `Dropout` layer.\n",
    "4. `MLPBlock`: Final stages of the transformer block. `Dense` layer → `Dense` layer → `Dropout` layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68742",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3a. Layer normalization\n",
    "\n",
    "Transformers replace batch normalization with **layer normalization**. Fortunately, layer normalization (\"layer norm\") is much simpler to implement than batch normalization because it does NOT require any special handling of training and non-training network state and there are no moving averages to manage! If we think of batch norm as the middle of the netIn and netAct \"sandwich\", layer norm shuffles the order and becomes the \"bottom bun\":\n",
    "\n",
    "Layer norm → netIn → netAct\n",
    "\n",
    "Make the following updates to `layer.py` to add support for layer normalization:\n",
    "\n",
    "1. `Layer` constructor: If you are not already, set the parameter `do_layer_norm` as an instance variable.\n",
    "2. Implement the `init_layernorm_params` method in `Layer` to initialize the parameters related to layer norm.\n",
    "3. Implement the `compute_layer_norm` method in `Layer` to compute the layer normalization on the input the layer receives from the previous layer/block.\n",
    "4. `Layer` `__call__` method: Add code to support Layer norm BEFORE computing net_in. If we are doing layer norm in the layer, call `compute_layer_norm` on the layer's input. Reassign `x` as the output of the layer norm computation. If the layer norm gain parameter is still `None` before computing the layer norm, call the `init_layernorm_params` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "6ec442",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d294",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Test: Layer normalization (2D input, linear activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6469f6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your netActs are:\n",
      "tf.Tensor(\n",
      "[[ 0.4998 -0.2505  1.0032 -1.4304]\n",
      " [ 0.5902 -0.1433  1.1012 -1.5475]], shape=(2, 4), dtype=float32)\n",
      "and should be:\n",
      "tf.Tensor(\n",
      "[[ 0.4998 -0.2505  1.0032 -1.4304]\n",
      " [ 0.5902 -0.1433  1.1012 -1.5475]], shape=(2, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(0)\n",
    "x_test = tf.random.uniform(shape=(2, 3))\n",
    "test_dense = Dense('testDense', 4, activation='linear', wt_init='he', do_layer_norm=True)\n",
    "test_net_acts = test_dense(x_test)\n",
    "print('Your netActs are:')\n",
    "print(test_net_acts)\n",
    "print('and should be:')\n",
    "print('''tf.Tensor(\n",
    "[[ 0.4998 -0.2505  1.0032 -1.4304]\n",
    " [ 0.5902 -0.1433  1.1012 -1.5475]], shape=(2, 4), dtype=float32)''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c79e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Test: Layer normalization (2D input, ReLU activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f97bdc",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your netActs are:\n",
      "tf.Tensor(\n",
      "[[0.4429 1.035  0.    ]\n",
      " [1.2696 0.5866 0.8557]\n",
      " [0.     0.     2.2657]\n",
      " [0.     0.     2.0688]], shape=(4, 3), dtype=float32)\n",
      "and should be:\n",
      "tf.Tensor(\n",
      "[[0.4429 1.035  0.    ]\n",
      " [1.2696 0.5866 0.8557]\n",
      " [0.     0.     2.2657]\n",
      " [0.     0.     2.0688]], shape=(4, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "x_test = tf.random.uniform(shape=(4, 7))\n",
    "test_dense = Dense('testDense', 3, activation='relu', wt_init='he', do_layer_norm=True)\n",
    "test_net_acts = test_dense(x_test)\n",
    "print('Your netActs are:')\n",
    "print(test_net_acts)\n",
    "print('and should be:')\n",
    "print('''tf.Tensor(\n",
    "[[0.4429 1.035  0.    ]\n",
    " [1.2696 0.5866 0.8557]\n",
    " [0.     0.     2.2657]\n",
    " [0.     0.     2.0688]], shape=(4, 3), dtype=float32)''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732532",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Test: Layer normalization (3D input, linear activation)\n",
    "\n",
    "3D input to a Dense layer seems odd, but this will happen due to the presence of the sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "bd7df5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your netActs are:\n",
      "tf.Tensor(\n",
      "[[[ 0.5571  1.7315  1.3083 -0.7988 -1.6684]\n",
      "  [ 0.5577  0.2769  1.8077  0.0518 -0.9832]\n",
      "  [-0.228  -2.0974 -0.0605  1.1388  1.3377]\n",
      "  [ 0.5715  1.6396  1.3886 -0.7396 -1.647 ]]\n",
      "\n",
      " [[-0.5426 -0.1613 -1.7958 -0.1136  0.9057]\n",
      "  [-0.1164  1.5696 -0.9337 -0.9621 -0.5623]\n",
      "  [-0.1331 -2.0135  0.2345  1.1261  1.1531]\n",
      "  [ 0.5502  1.7635  1.2736 -0.8201 -1.6728]]], shape=(2, 4, 5), dtype=float32)\n",
      "and should be:\n",
      "tf.Tensor(\n",
      "[[[ 0.5571  1.7315  1.3083 -0.7988 -1.6684]\n",
      "  [ 0.5577  0.2769  1.8077  0.0518 -0.9832]\n",
      "  [-0.228  -2.0974 -0.0605  1.1388  1.3377]\n",
      "  [ 0.5715  1.6396  1.3886 -0.7396 -1.647 ]]\n",
      "\n",
      " [[-0.5426 -0.1613 -1.7958 -0.1136  0.9057]\n",
      "  [-0.1164  1.5696 -0.9337 -0.9621 -0.5623]\n",
      "  [-0.1331 -2.0135  0.2345  1.1261  1.1531]\n",
      "  [ 0.5502  1.7635  1.2736 -0.8201 -1.6728]]], shape=(2, 4, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(2)\n",
    "x_test = tf.random.uniform(shape=(2, 4, 3))\n",
    "test_dense = Dense('testDense', 5, activation='linear', wt_init='he', do_layer_norm=True)\n",
    "test_net_acts = test_dense(x_test)\n",
    "print('Your netActs are:')\n",
    "print(test_net_acts)\n",
    "print('and should be:')\n",
    "print('''tf.Tensor(\n",
    "[[[ 0.5571  1.7315  1.3083 -0.7988 -1.6684]\n",
    "  [ 0.5577  0.2769  1.8077  0.0518 -0.9832]\n",
    "  [-0.228  -2.0974 -0.0605  1.1388  1.3377]\n",
    "  [ 0.5715  1.6396  1.3886 -0.7396 -1.647 ]]\n",
    "\n",
    " [[-0.5426 -0.1613 -1.7958 -0.1136  0.9057]\n",
    "  [-0.1164  1.5696 -0.9337 -0.9621 -0.5623]\n",
    "  [-0.1331 -2.0135  0.2345  1.1261  1.1531]\n",
    "  [ 0.5502  1.7635  1.2736 -0.8201 -1.6728]]], shape=(2, 4, 5), dtype=float32)''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df814",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3b. Implement `QueryKeyValueBlock`\n",
    "\n",
    "The class for this block is in `transformer_blocks.py`. This block handles the projection/embedding/mapping of the input signal into the three parallel `Dense` layers that learn the attention queries, keys, and values. It projects the input signal from `H_embed` in the `Embedding` layer to `H_qkv` units in each of the queries, keys, and values `Dense` layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c1d9fc",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from transformer_blocks import QueryKeyValueBlock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab488b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Test: `QueryKeyValueBlock`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "bcd084",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your queries shape=(2, 4, 3) and should be (2, 4, 3)\n",
      "Your keys shape=(2, 4, 3) and should be (2, 4, 3)\n",
      "Your values shape=(2, 4, 3) and should be (2, 4, 3)\n",
      "Your queries for 1st sample:\n",
      "[[-0.1059  0.0967  0.9469]\n",
      " [ 0.565  -0.3605 -0.0556]\n",
      " [-2.3749  0.6514 -1.7692]\n",
      " [-2.7052  1.3316  0.6261]]\n",
      "and they should be:\n",
      "[[-0.1059  0.0967  0.9469]\n",
      " [ 0.565  -0.3605 -0.0556]\n",
      " [-2.3749  0.6514 -1.7692]\n",
      " [-2.7052  1.3316  0.6261]]\n",
      "Your keys for 2nd sample:\n",
      "[[ 1.8961  1.0138  0.2909]\n",
      " [ 1.1773  1.6024 -0.6112]\n",
      " [ 0.8273  2.0583  0.5604]\n",
      " [-0.6342 -0.1947 -0.1052]]\n",
      "and they should be:\n",
      "[[ 1.8961  1.0138  0.2909]\n",
      " [ 1.1773  1.6024 -0.6112]\n",
      " [ 0.8273  2.0583  0.5604]\n",
      " [-0.6342 -0.1947 -0.1052]]\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(0)\n",
    "x_q = tf.random.uniform(shape=(2, 4, 7))\n",
    "x_k = tf.random.uniform(shape=(2, 4, 7))\n",
    "x_v = tf.random.uniform(shape=(2, 4, 7))\n",
    "qkv = QueryKeyValueBlock('test', units=3, prev_layer_or_block=None)\n",
    "act_q, act_k, act_v = qkv(x_q, x_k, x_v)\n",
    "print(f'Your queries shape={act_q.shape} and should be (2, 4, 3)')\n",
    "print(f'Your keys shape={act_q.shape} and should be (2, 4, 3)')\n",
    "print(f'Your values shape={act_q.shape} and should be (2, 4, 3)')\n",
    "print(f'Your queries for 1st sample:')\n",
    "print(act_q[0].numpy())\n",
    "print('and they should be:')\n",
    "print('''[[-0.1059  0.0967  0.9469]\n",
    " [ 0.565  -0.3605 -0.0556]\n",
    " [-2.3749  0.6514 -1.7692]\n",
    " [-2.7052  1.3316  0.6261]]''')\n",
    "print(f'Your keys for 2nd sample:')\n",
    "print(act_k[1].numpy())\n",
    "print('and they should be:')\n",
    "print('''[[ 1.8961  1.0138  0.2909]\n",
    " [ 1.1773  1.6024 -0.6112]\n",
    " [ 0.8273  2.0583  0.5604]\n",
    " [-0.6342 -0.1947 -0.1052]]''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "c09498",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your values for 1st sample:\n",
      "[[ 2.8008 -0.1346  0.6618]\n",
      " [-1.1517  0.3497 -0.1807]\n",
      " [ 2.8561 -0.2845  2.1165]\n",
      " [-1.9511  1.0497 -0.966 ]]\n",
      "and they should be:\n",
      "[[ 2.8008 -0.1346  0.6618]\n",
      " [-1.1517  0.3497 -0.1807]\n",
      " [ 2.8561 -0.2845  2.1165]\n",
      " [-1.9511  1.0497 -0.966 ]]\n"
     ]
    }
   ],
   "source": [
    "print(f'Your values for 1st sample:')\n",
    "print(act_v[0].numpy())\n",
    "print('and they should be:')\n",
    "print('''[[ 2.8008 -0.1346  0.6618]\n",
    " [-1.1517  0.3497 -0.1807]\n",
    " [ 2.8561 -0.2845  2.1165]\n",
    " [-1.9511  1.0497 -0.966 ]]''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6fe3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3c. Implement Multi-headed attention layer\n",
    "\n",
    "Multi-headed attention is a hybrid between a \"layer\" and a \"block\". It would be a layer, except it has a Dropout layer built into its core operations, which makes it more like a block. In this project, we treat it as a `Block` because it technically has the Dropout layer inside it. Implement multi-headed attention in `AttentionBlock` and test your implementation below.\n",
    "\n",
    "#### Attention equations\n",
    "\n",
    "After some reformatting, the 1st stage of attention ($A_1$) is computed as:\n",
    "\n",
    "$$\n",
    "A_1 = \\frac{QK^T}{g_A}\n",
    "$$\n",
    "\n",
    "where $Q$ are the queries, $K$ are the keys, and $g_A$ is the attention gain. $A$ has shape `(N, A, T, T)`, where `A` is the number of attention heads and `T` is the sequence length. $Q$ has shape `(N, A, T, H_qkv/A)` and $K^T$ has shape `(N, A, H_qkv/A, T)`, where `H_qkv` is the number of number of units in the query, key, and value `Dense` layers in the `QueryKeyValueBlock` block. The attention gain is:\n",
    "\n",
    "$$\n",
    "g_A = 1/\\sqrt{H_{qkv}/A}\n",
    "$$\n",
    "\n",
    "Next:\n",
    "- After applying the causal mask to $A_1$ to get $A_2$, we apply the softmax: $A_3 = \\text{softmax}(A_2)$.\n",
    "- We apply dropout to the attention values to obtain $A_4$.\n",
    "- Finally, we compute the attention output:\n",
    "\n",
    "$$\n",
    "A_5 = A_4V\n",
    "$$\n",
    "\n",
    "where $V$ are the values (shape: `(N, A, T, H_qkv/A)`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "152a47",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from transformer_blocks import AttentionBlock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0777a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Test: `AttentionBlock` (no causal mask, no dropout) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "87c514",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your attention output is:\n",
      "tf.Tensor(\n",
      "[[[0.3637 0.7639 0.472  0.5611 0.687  0.1123 0.5028 0.5486]\n",
      "  [0.3632 0.767  0.457  0.5766 0.6813 0.1139 0.5032 0.5514]\n",
      "  [0.365  0.765  0.4721 0.5543 0.6693 0.1033 0.502  0.551 ]]\n",
      "\n",
      " [[0.5859 0.2788 0.6017 0.7209 0.6321 0.4318 0.6108 0.7472]\n",
      "  [0.5928 0.3031 0.6216 0.7441 0.6174 0.4281 0.6139 0.7434]\n",
      "  [0.5788 0.3034 0.6145 0.7363 0.5735 0.4389 0.607  0.7457]]], shape=(2, 3, 8), dtype=float32)\n",
      "and it should be:\n",
      "tf.Tensor(\n",
      "[[[0.3637 0.7639 0.472  0.5611 0.687  0.1123 0.5028 0.5486]\n",
      "  [0.3632 0.767  0.457  0.5766 0.6813 0.1139 0.5032 0.5514]\n",
      "  [0.365  0.765  0.4721 0.5543 0.6693 0.1033 0.502  0.551 ]]\n",
      "\n",
      " [[0.5859 0.2788 0.6017 0.7209 0.6321 0.4318 0.6108 0.7472]\n",
      "  [0.5928 0.3031 0.6216 0.7441 0.6174 0.4281 0.6139 0.7434]\n",
      "  [0.5788 0.3034 0.6145 0.7363 0.5735 0.4389 0.607  0.7457]]], shape=(2, 3, 8), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(0)\n",
    "q = tf.random.uniform(shape=(2, 3, 8))\n",
    "k = tf.random.uniform(shape=(2, 3, 8))\n",
    "v = tf.random.uniform(shape=(2, 3, 8))\n",
    "\n",
    "aBlock = AttentionBlock('testAttnBlock', num_heads=4, units=8, dropout_rate=0., causal=False, prev_layer_or_block=None)\n",
    "attnOut = aBlock(q, k, v)\n",
    "print('Your attention output is:')\n",
    "print(attnOut)\n",
    "print('and it should be:')\n",
    "print('''tf.Tensor(\n",
    "[[[0.3637 0.7639 0.472  0.5611 0.687  0.1123 0.5028 0.5486]\n",
    "  [0.3632 0.767  0.457  0.5766 0.6813 0.1139 0.5032 0.5514]\n",
    "  [0.365  0.765  0.4721 0.5543 0.6693 0.1033 0.502  0.551 ]]\n",
    "\n",
    " [[0.5859 0.2788 0.6017 0.7209 0.6321 0.4318 0.6108 0.7472]\n",
    "  [0.5928 0.3031 0.6216 0.7441 0.6174 0.4281 0.6139 0.7434]\n",
    "  [0.5788 0.3034 0.6145 0.7363 0.5735 0.4389 0.607  0.7457]]], shape=(2, 3, 8), dtype=float32)''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c32a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Test: `AttentionBlock` (Causal mask, no dropout) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "27cf50",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your attention output is:\n",
      "tf.Tensor(\n",
      "[[[0.1952 0.7402 0.4878 0.8753 0.4071 0.0145 0.7095 0.3655]\n",
      "  [0.3854 0.8194 0.3147 0.7147 0.5393 0.0098 0.5311 0.4688]\n",
      "  [0.365  0.765  0.4721 0.5543 0.6693 0.1033 0.502  0.551 ]]\n",
      "\n",
      " [[0.1698 0.2402 0.9734 0.983  0.0376 0.4883 0.506  0.9527]\n",
      "  [0.5098 0.436  0.7985 0.9104 0.343  0.4935 0.6095 0.874 ]\n",
      "  [0.5788 0.3034 0.6145 0.7363 0.5735 0.4389 0.607  0.7457]]], shape=(2, 3, 8), dtype=float32)\n",
      "and it should be:\n",
      "tf.Tensor(\n",
      "[[[0.1952 0.7402 0.4878 0.8753 0.4071 0.0145 0.7095 0.3655]\n",
      "  [0.3854 0.8194 0.3147 0.7147 0.5393 0.0098 0.5311 0.4688]\n",
      "  [0.365  0.765  0.4721 0.5543 0.6693 0.1033 0.502  0.551 ]]\n",
      "\n",
      " [[0.1698 0.2402 0.9734 0.983  0.0376 0.4883 0.506  0.9527]\n",
      "  [0.5098 0.436  0.7985 0.9104 0.343  0.4935 0.6095 0.874 ]\n",
      "  [0.5788 0.3034 0.6145 0.7363 0.5735 0.4389 0.607  0.7457]]], shape=(2, 3, 8), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(0)\n",
    "q = tf.random.uniform(shape=(2, 3, 8))\n",
    "k = tf.random.uniform(shape=(2, 3, 8))\n",
    "v = tf.random.uniform(shape=(2, 3, 8))\n",
    "\n",
    "aBlock = AttentionBlock('testAttnBlock', num_heads=4, units=8, dropout_rate=0., causal=True, prev_layer_or_block=None)\n",
    "attnOut = aBlock(q, k, v)\n",
    "print('Your attention output is:')\n",
    "print(attnOut)\n",
    "print('and it should be:')\n",
    "print('''tf.Tensor(\n",
    "[[[0.1952 0.7402 0.4878 0.8753 0.4071 0.0145 0.7095 0.3655]\n",
    "  [0.3854 0.8194 0.3147 0.7147 0.5393 0.0098 0.5311 0.4688]\n",
    "  [0.365  0.765  0.4721 0.5543 0.6693 0.1033 0.502  0.551 ]]\n",
    "\n",
    " [[0.1698 0.2402 0.9734 0.983  0.0376 0.4883 0.506  0.9527]\n",
    "  [0.5098 0.436  0.7985 0.9104 0.343  0.4935 0.6095 0.874 ]\n",
    "  [0.5788 0.3034 0.6145 0.7363 0.5735 0.4389 0.607  0.7457]]], shape=(2, 3, 8), dtype=float32)''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3102",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Test 1/2: `AttentionBlock` (Causal mask, Dropout)\n",
    "\n",
    "Training mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "cd0797",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your attention output is:\n",
      "tf.Tensor(\n",
      "[[[0.     0.     0.     0.4889 0.7261 0.0606]\n",
      "  [0.626  0.8372 0.629  0.2683 0.3985 0.0333]]\n",
      "\n",
      " [[1.0607 1.1801 0.658  0.4777 0.3498 0.0422]\n",
      "  [0.7998 0.6479 0.9327 0.7146 0.5982 0.3584]]], shape=(2, 2, 6), dtype=float32)\n",
      "and it should be:\n",
      "tf.Tensor(\n",
      "[[[1.0366 0.7928 0.6434 0.     0.     0.    ]\n",
      "  [0.626  0.8372 0.629  0.4634 0.685  0.1583]]\n",
      "\n",
      " [[0.     0.     0.     0.     0.     0.    ]\n",
      "  [0.2705 0.059  0.6044 0.7146 0.5982 0.3584]]], shape=(2, 2, 6), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "q = tf.random.uniform(shape=(2, 2, 6))\n",
    "k = tf.random.uniform(shape=(2, 2, 6))\n",
    "v = tf.random.uniform(shape=(2, 2, 6))\n",
    "\n",
    "tf.random.set_seed(2)\n",
    "aBlock = AttentionBlock('testAttnBlock', num_heads=2, units=6, dropout_rate=0.2, causal=True, prev_layer_or_block=None)\n",
    "aBlock.set_mode(is_training=True)\n",
    "attnOut = aBlock(q, k, v)\n",
    "print('Your attention output is:')\n",
    "print(attnOut)\n",
    "print('and it should be:')\n",
    "print('''tf.Tensor(\n",
    "[[[1.0366 0.7928 0.6434 0.     0.     0.    ]\n",
    "  [0.626  0.8372 0.629  0.4634 0.685  0.1583]]\n",
    "\n",
    " [[0.     0.     0.     0.     0.     0.    ]\n",
    "  [0.2705 0.059  0.6044 0.7146 0.5982 0.3584]]], shape=(2, 2, 6), dtype=float32)''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ceadb",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Option 2 (for alternate dropout implementation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "574b12",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your attention output is:\n",
      "tf.Tensor(\n",
      "[[[0.     0.     0.     0.4889 0.7261 0.0606]\n",
      "  [0.626  0.8372 0.629  0.2683 0.3985 0.0333]]\n",
      "\n",
      " [[1.0607 1.1801 0.658  0.4777 0.3498 0.0422]\n",
      "  [0.7998 0.6479 0.9327 0.7146 0.5982 0.3584]]], shape=(2, 2, 6), dtype=float32)\n",
      "and it should be:\n",
      "tf.Tensor(\n",
      "[[[0.     0.     0.     0.4889 0.7261 0.0606]\n",
      "  [0.626  0.8372 0.629  0.2683 0.3985 0.0333]]\n",
      "\n",
      " [[1.0607 1.1801 0.658  0.4777 0.3498 0.0422]\n",
      "  [0.7998 0.6479 0.9327 0.7146 0.5982 0.3584]]], shape=(2, 2, 6), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "q = tf.random.uniform(shape=(2, 2, 6))\n",
    "k = tf.random.uniform(shape=(2, 2, 6))\n",
    "v = tf.random.uniform(shape=(2, 2, 6))\n",
    "\n",
    "tf.random.set_seed(2)\n",
    "aBlock = AttentionBlock('testAttnBlock', num_heads=2, units=6, dropout_rate=0.2, causal=True, prev_layer_or_block=None)\n",
    "aBlock.set_mode(is_training=True)\n",
    "attnOut = aBlock(q, k, v)\n",
    "print('Your attention output is:')\n",
    "print(attnOut)\n",
    "print('and it should be:')\n",
    "print('''tf.Tensor(\n",
    "[[[0.     0.     0.     0.4889 0.7261 0.0606]\n",
    "  [0.626  0.8372 0.629  0.2683 0.3985 0.0333]]\n",
    "\n",
    " [[1.0607 1.1801 0.658  0.4777 0.3498 0.0422]\n",
    "  [0.7998 0.6479 0.9327 0.7146 0.5982 0.3584]]], shape=(2, 2, 6), dtype=float32)''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7653",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Test 2/2: `AttentionBlock` (Causal mask, Dropout)\n",
    "\n",
    "Predict mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "195994",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your attention output is:\n",
      "tf.Tensor(\n",
      "[[[0.8293 0.6342 0.5147 0.3911 0.5809 0.0485]\n",
      "  [0.5008 0.6698 0.5032 0.3708 0.548  0.1266]]\n",
      "\n",
      " [[0.8486 0.9441 0.5264 0.3821 0.2798 0.0338]\n",
      "  [0.6398 0.5183 0.7462 0.5717 0.4785 0.2867]]], shape=(2, 2, 6), dtype=float32)\n",
      "and it should be:\n",
      "tf.Tensor(\n",
      "[[[0.8293 0.6342 0.5147 0.3911 0.5809 0.0485]\n",
      "  [0.5008 0.6698 0.5032 0.3708 0.548  0.1266]]\n",
      "\n",
      " [[0.8486 0.9441 0.5264 0.3821 0.2798 0.0338]\n",
      "  [0.6398 0.5183 0.7462 0.5717 0.4785 0.2867]]], shape=(2, 2, 6), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "aBlock.set_mode(is_training=False)\n",
    "attnOut = aBlock(q, k, v)\n",
    "print('Your attention output is:')\n",
    "print(attnOut)\n",
    "print('and it should be:')\n",
    "print('''tf.Tensor(\n",
    "[[[0.8293 0.6342 0.5147 0.3911 0.5809 0.0485]\n",
    "  [0.5008 0.6698 0.5032 0.3708 0.548  0.1266]]\n",
    "\n",
    " [[0.8486 0.9441 0.5264 0.3821 0.2798 0.0338]\n",
    "  [0.6398 0.5183 0.7462 0.5717 0.4785 0.2867]]], shape=(2, 2, 6), dtype=float32)''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3807e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3d. Implement `MultiHeadAttentionBlock`\n",
    "\n",
    "Whenever we apply multi-head attention, we tend to process the inputs with the same 4 layers:\n",
    "1. Project the input from the `Embedding` layer (or previous Transformer Block) into query, key, and value. Units goes from `H_embed` → `H_qkv`\n",
    "2. Apply multi-headed attention (*involves the awkward Dropout layer nested within*). Still have `H_qkv` neurons.\n",
    "3. We wish to go back to the original number of neurons (`H_embed`) so we have a `Dense` layer that maps neurons `H_qkv` → `H_embed`.\n",
    "4. We apply another `Dropout` layer.\n",
    "\n",
    "To help automate/bundle these steps, implement them within a repeatable block called `MultiHeadAttentionBlock`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "8acb4b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from transformer_blocks import MultiHeadAttentionBlock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55075a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Test: `MultiHeadAttentionBlock` (No Dropout) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "a7baf2",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your attention block output is:\n",
      "tf.Tensor(\n",
      "[[[-0.5709 -1.4398  0.6815  1.401   0.7574 -1.1723]\n",
      "  [-0.6402 -0.6875  0.6452  1.0173  0.4651 -1.6087]\n",
      "  [-0.7561 -0.5228  0.4209  0.6666  0.5477 -1.1205]]\n",
      "\n",
      " [[ 1.593  -1.5829  0.6069 -0.7066  0.6006  0.1112]\n",
      "  [ 0.6322  0.054   0.2551 -0.4053  0.1574 -0.1207]\n",
      "  [ 0.2254  0.7104  0.0982 -0.428  -0.073  -0.2994]]], shape=(2, 3, 6), dtype=float32)\n",
      "and it should be:\n",
      "tf.Tensor(\n",
      "[[[-0.5709 -1.4398  0.6815  1.401   0.7574 -1.1723]\n",
      "  [-0.6402 -0.6875  0.6452  1.0173  0.4651 -1.6087]\n",
      "  [-0.7561 -0.5228  0.4209  0.6666  0.5477 -1.1205]]\n",
      "\n",
      " [[ 1.593  -1.5829  0.6069 -0.7066  0.6006  0.1112]\n",
      "  [ 0.6322  0.054   0.2551 -0.4053  0.1574 -0.1207]\n",
      "  [ 0.2254  0.7104  0.0982 -0.428  -0.073  -0.2994]]], shape=(2, 3, 6), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "x_test = tf.random.uniform(shape=(2, 3, 5))\n",
    "\n",
    "tf.random.set_seed(2)\n",
    "mhaBlock = MultiHeadAttentionBlock('testMHABlock',\n",
    "                                   num_heads=2,\n",
    "                                   units=6,\n",
    "                                   dropout_rate=0.,\n",
    "                                   causal=True,\n",
    "                                   prev_layer_or_block=None)\n",
    "attnOut = mhaBlock(x_test)\n",
    "print('Your attention block output is:')\n",
    "print(attnOut)\n",
    "print('and it should be:')\n",
    "print('''tf.Tensor(\n",
    "[[[-0.5709 -1.4398  0.6815  1.401   0.7574 -1.1723]\n",
    "  [-0.6402 -0.6875  0.6452  1.0173  0.4651 -1.6087]\n",
    "  [-0.7561 -0.5228  0.4209  0.6666  0.5477 -1.1205]]\n",
    "\n",
    " [[ 1.593  -1.5829  0.6069 -0.7066  0.6006  0.1112]\n",
    "  [ 0.6322  0.054   0.2551 -0.4053  0.1574 -0.1207]\n",
    "  [ 0.2254  0.7104  0.0982 -0.428  -0.073  -0.2994]]], shape=(2, 3, 6), dtype=float32)''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbaa9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Test 1/2: `MultiHeadAttentionBlock` (With Dropout)\n",
    "\n",
    "Training mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "799a62",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your attention block output is:\n",
      "tf.Tensor(\n",
      "[[[-0.6916  0.     -1.9805  0.     -5.2524 -1.4639]\n",
      "  [-6.0596  0.      0.      0.6071  0.     -0.7779]\n",
      "  [ 0.      2.6097  0.      1.3048 -3.5101 -0.8195]]\n",
      "\n",
      " [[ 0.      0.      0.      0.      0.      0.    ]\n",
      "  [ 0.      0.      0.      0.      0.      0.    ]\n",
      "  [ 0.      0.      0.      0.      0.      0.    ]]], shape=(2, 3, 6), dtype=float32)\n",
      "and it should be:\n",
      "tf.Tensor(\n",
      "[[[-0.      3.5339  0.     -0.0559  0.      0.    ]\n",
      "  [ 0.      0.      0.      0.      0.      0.    ]\n",
      "  [-2.4667  0.      0.5861 -0.      0.     -0.    ]]\n",
      "\n",
      " [[ 0.     -2.8067 -2.7201 -0.      2.6466  1.5454]\n",
      "  [-0.      0.     -0.     -0.      1.8928  1.4068]\n",
      "  [-1.6319  0.      0.8425 -1.1164  0.      0.    ]]], shape=(2, 3, 6), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "x_test = tf.random.uniform(shape=(2, 3, 5))\n",
    "\n",
    "tf.random.set_seed(2)\n",
    "mhaBlock = MultiHeadAttentionBlock('testMHABlock',\n",
    "                                   num_heads=2,\n",
    "                                   units=6,\n",
    "                                   dropout_rate=0.5,\n",
    "                                   causal=True,\n",
    "                                   prev_layer_or_block=None)\n",
    "mhaBlock.set_mode(is_training=True)\n",
    "attnOut = mhaBlock(x_test)\n",
    "print('Your attention block output is:')\n",
    "print(attnOut)\n",
    "print('and it should be:')\n",
    "print('''tf.Tensor(\n",
    "[[[-0.      3.5339  0.     -0.0559  0.      0.    ]\n",
    "  [ 0.      0.      0.      0.      0.      0.    ]\n",
    "  [-2.4667  0.      0.5861 -0.      0.     -0.    ]]\n",
    "\n",
    " [[ 0.     -2.8067 -2.7201 -0.      2.6466  1.5454]\n",
    "  [-0.      0.     -0.     -0.      1.8928  1.4068]\n",
    "  [-1.6319  0.      0.8425 -1.1164  0.      0.    ]]], shape=(2, 3, 6), dtype=float32)''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a024ab",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Option 2 (for alternate dropout implementation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "27ed9c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your attention block output is:\n",
      "tf.Tensor(\n",
      "[[[-0.6916  0.     -1.9805  0.     -5.2524 -1.4639]\n",
      "  [-6.0596  0.      0.      0.6071  0.     -0.7779]\n",
      "  [ 0.      2.6097  0.      1.3048 -3.5101 -0.8195]]\n",
      "\n",
      " [[ 0.      0.      0.      0.      0.      0.    ]\n",
      "  [ 0.      0.      0.      0.      0.      0.    ]\n",
      "  [ 0.      0.      0.      0.      0.      0.    ]]], shape=(2, 3, 6), dtype=float32)\n",
      "and it should be:\n",
      "tf.Tensor(\n",
      "[[[-0.6916  0.     -1.9805  0.     -5.2524 -1.4639]\n",
      "  [-6.0596  0.      0.      0.6071  0.     -0.7779]\n",
      "  [ 0.      2.6097  0.      1.3048 -3.5101 -0.8195]]\n",
      "\n",
      " [[ 0.      0.      0.      0.      0.      0.    ]\n",
      "  [ 0.      0.      0.      0.      0.      0.    ]\n",
      "  [ 0.      0.      0.      0.      0.      0.    ]]], shape=(2, 3, 6), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "x_test = tf.random.uniform(shape=(2, 3, 5))\n",
    "\n",
    "tf.random.set_seed(2)\n",
    "mhaBlock = MultiHeadAttentionBlock('testMHABlock',\n",
    "                                   num_heads=2,\n",
    "                                   units=6,\n",
    "                                   dropout_rate=0.5,\n",
    "                                   causal=True,\n",
    "                                   prev_layer_or_block=None)\n",
    "mhaBlock.set_mode(is_training=True)\n",
    "attnOut = mhaBlock(x_test)\n",
    "print('Your attention block output is:')\n",
    "print(attnOut)\n",
    "print('and it should be:')\n",
    "print('''tf.Tensor(\n",
    "[[[-0.6916  0.     -1.9805  0.     -5.2524 -1.4639]\n",
    "  [-6.0596  0.      0.      0.6071  0.     -0.7779]\n",
    "  [ 0.      2.6097  0.      1.3048 -3.5101 -0.8195]]\n",
    "\n",
    " [[ 0.      0.      0.      0.      0.      0.    ]\n",
    "  [ 0.      0.      0.      0.      0.      0.    ]\n",
    "  [ 0.      0.      0.      0.      0.      0.    ]]], shape=(2, 3, 6), dtype=float32)''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23d76",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Test 2/2: `MultiHeadAttentionBlock` (With Dropout)\n",
    "\n",
    "Predict mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "435807",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your attention block output is:\n",
      "tf.Tensor(\n",
      "[[[-1.1534  1.123  -0.4634  0.4363 -0.8906 -0.2021]\n",
      "  [-1.5149  1.8546 -0.2039  0.1518 -0.7866 -0.1945]\n",
      "  [-1.1517  1.6016 -0.0353  0.1228 -0.5384 -0.245 ]]\n",
      "\n",
      " [[ 0.0518 -0.7017 -0.68   -0.2356  0.6617  0.3863]\n",
      "  [-0.2434  0.0704 -0.0387 -0.2261  0.4732  0.3517]\n",
      "  [-0.408   0.5133  0.2106 -0.2791  0.3466  0.3328]]], shape=(2, 3, 6), dtype=float32)\n",
      "and it should be:\n",
      "tf.Tensor(\n",
      "[[[-1.1534  1.123  -0.4634  0.4363 -0.8906 -0.2021]\n",
      "  [-1.5149  1.8546 -0.2039  0.1518 -0.7866 -0.1945]\n",
      "  [-1.1517  1.6016 -0.0353  0.1228 -0.5384 -0.245 ]]\n",
      "\n",
      " [[ 0.0518 -0.7017 -0.68   -0.2356  0.6617  0.3863]\n",
      "  [-0.2434  0.0704 -0.0387 -0.2261  0.4732  0.3517]\n",
      "  [-0.408   0.5133  0.2106 -0.2791  0.3466  0.3328]]], shape=(2, 3, 6), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "mhaBlock.set_mode(is_training=False)\n",
    "attnOut = mhaBlock(x_test)\n",
    "print('Your attention block output is:')\n",
    "print(attnOut)\n",
    "print('and it should be:')\n",
    "print('''tf.Tensor(\n",
    "[[[-1.1534  1.123  -0.4634  0.4363 -0.8906 -0.2021]\n",
    "  [-1.5149  1.8546 -0.2039  0.1518 -0.7866 -0.1945]\n",
    "  [-1.1517  1.6016 -0.0353  0.1228 -0.5384 -0.245 ]]\n",
    "\n",
    " [[ 0.0518 -0.7017 -0.68   -0.2356  0.6617  0.3863]\n",
    "  [-0.2434  0.0704 -0.0387 -0.2261  0.4732  0.3517]\n",
    "  [-0.408   0.5133  0.2106 -0.2791  0.3466  0.3328]]], shape=(2, 3, 6), dtype=float32)''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d430bb",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3e. Implement `MLPBlock`\n",
    "\n",
    "The last major component of the Transformer Block is a sub MLP block that occurs after the processing in the `MultiHeadAttentionBlock`. It contains two `Dense` layers followed by a `Dropout` layer. The `Dense` layers implement a bottleneck: increasing units by 4x, then decreasing the number of units back to the baseline level. *This is somewhat analogous to ResNet's Bottleneck Block*.\n",
    "\n",
    "In the first `Dense` layer, when the units expand to 4x the baseline, a new activation function tends to be used: **Gaussian Error Linear Unit (GELU)**. Before you implement and test the `MLPBlock`, first:\n",
    "1. Implement GELU in the `gelu` method of your `Layer` class (*see below equation*)\n",
    "2. Add support for GELU activation in the `compute_net_activation` method of your `Layer` class.\n",
    "\n",
    "Here is a refresher on the equation:\n",
    "\n",
    "$$\n",
    "\\text{GELU}(\\text{netIn}) = 0.5 x \\left(1 + \\tanh\\left[\\sqrt{\\frac{2}{\\pi}} \\left(netIn + 0.044715 netIn^3\\right)\\right]\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "09b9a4",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from transformer_blocks import MLPBlock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1f16",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Test: GELU activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "d26b6c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "netActs after applying GELU are:\n",
      "[[ 0.0007  0.0004  0.0002 -0.0003 -0.0002]]\n",
      "and should be\n",
      "[[ 0.0007  0.0004  0.0002 -0.0003 -0.0002]]\n",
      "netActs after applying GELU (layer_norm turned on) are:\n",
      "[[-0.0024  0.0023 -0.0023  0.0002 -0.0003  0.0011]]\n",
      "and should be\n",
      "[[-0.0024  0.0023 -0.0023  0.0002 -0.0003  0.0011]]\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(0)\n",
    "x_test = tf.random.uniform(shape=(1, 7))\n",
    "\n",
    "tf.random.set_seed(1)\n",
    "denseTest = Dense('testDense', units=5, activation='gelu')\n",
    "test_out_1 = denseTest(x_test)\n",
    "print(f'netActs after applying GELU are:\\n{test_out_1.numpy()}\\nand should be\\n[[ 0.0007  0.0004  0.0002 -0.0003 -0.0002]]')\n",
    "\n",
    "tf.random.set_seed(2)\n",
    "denseTest = Dense('testDense', units=6, activation='gelu', do_layer_norm=True)\n",
    "test_out_1 = denseTest(x_test)\n",
    "print(f'netActs after applying GELU (layer_norm turned on) are:\\n{test_out_1.numpy()}\\nand should be\\n[[-0.0024  0.0023 -0.0023  0.0002 -0.0003  0.0011]]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07adc",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Test: `MLPBlock` (No dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "69481e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "netActs from your MLPBlock are:\n",
      "tf.Tensor(\n",
      "[[[-0.1837 -0.044  -0.2113 -0.1475 -0.2642  0.3548 -0.4907]\n",
      "  [-0.4057  0.1358 -0.0993 -0.4647 -0.4678 -0.1536 -0.1301]\n",
      "  [ 0.9095  0.152  -0.4679  0.2902 -0.7817  1.5217 -0.2833]]\n",
      "\n",
      " [[-0.4854  0.5821  0.1405  0.2118  0.602  -0.1737  0.5802]\n",
      "  [ 0.485  -0.5016 -0.0709 -0.1024 -0.6311  0.2167 -0.2006]\n",
      "  [ 0.0839 -0.1037 -0.0383 -0.1329  0.1339 -0.3871 -0.0003]]], shape=(2, 3, 7), dtype=float32)\n",
      "and should be:\n",
      "tf.Tensor(\n",
      "[[[-0.1837 -0.044  -0.2113 -0.1475 -0.2642  0.3548 -0.4907]\n",
      "  [-0.4057  0.1358 -0.0993 -0.4647 -0.4678 -0.1536 -0.1301]\n",
      "  [ 0.9095  0.152  -0.4679  0.2902 -0.7817  1.5217 -0.2833]]\n",
      "\n",
      " [[-0.4854  0.5821  0.1405  0.2118  0.602  -0.1737  0.5802]\n",
      "  [ 0.485  -0.5016 -0.0709 -0.1024 -0.6311  0.2167 -0.2006]\n",
      "  [ 0.0839 -0.1037 -0.0383 -0.1329  0.1339 -0.3871 -0.0003]]], shape=(2, 3, 7), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "x_test = tf.random.uniform(shape=(2, 3, 5))\n",
    "\n",
    "mlpblock = MLPBlock('testMLPBlock', units=7, prev_layer_or_block=None, dropout_rate=0.)\n",
    "test_net_acts = mlpblock(x_test)\n",
    "print('netActs from your MLPBlock are:')\n",
    "print(test_net_acts)\n",
    "print('and should be:')\n",
    "print('''tf.Tensor(\n",
    "[[[-0.1837 -0.044  -0.2113 -0.1475 -0.2642  0.3548 -0.4907]\n",
    "  [-0.4057  0.1358 -0.0993 -0.4647 -0.4678 -0.1536 -0.1301]\n",
    "  [ 0.9095  0.152  -0.4679  0.2902 -0.7817  1.5217 -0.2833]]\n",
    "\n",
    " [[-0.4854  0.5821  0.1405  0.2118  0.602  -0.1737  0.5802]\n",
    "  [ 0.485  -0.5016 -0.0709 -0.1024 -0.6311  0.2167 -0.2006]\n",
    "  [ 0.0839 -0.1037 -0.0383 -0.1329  0.1339 -0.3871 -0.0003]]], shape=(2, 3, 7), dtype=float32)''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bd58",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Test: `MLPBlock` (Dropout 1/2)\n",
    "\n",
    "Training mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "af79f7",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "netActs from your MLPBlock are:\n",
      "tf.Tensor(\n",
      "[[[ 0.9135 -1.0447 -0.2246  0.706  -1.1197]\n",
      "  [ 1.7503 -0.6826 -1.4628  0.0423 -1.8769]\n",
      "  [ 0.2141 -0.0222  0.      0.0865  0.232 ]]], shape=(1, 3, 5), dtype=float32)\n",
      "and should be:\n",
      "tf.Tensor(\n",
      "[[[ 0.9135 -1.0447 -0.2246  0.706  -1.1197]\n",
      "  [ 0.     -0.6826 -1.4628  0.0423 -0.    ]\n",
      "  [ 0.2141 -0.0222  0.0208  0.0865  0.232 ]]], shape=(1, 3, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "x_test = tf.random.uniform(shape=(1, 3, 4))\n",
    "\n",
    "mlpblock = MLPBlock('testMLPBlock', units=5, prev_layer_or_block=None, dropout_rate=0.2)\n",
    "mlpblock.set_mode(is_training=True)\n",
    "test_net_acts = mlpblock(x_test)\n",
    "print('netActs from your MLPBlock are:')\n",
    "print(test_net_acts)\n",
    "print('and should be:')\n",
    "print('''tf.Tensor(\n",
    "[[[ 0.9135 -1.0447 -0.2246  0.706  -1.1197]\n",
    "  [ 0.     -0.6826 -1.4628  0.0423 -0.    ]\n",
    "  [ 0.2141 -0.0222  0.0208  0.0865  0.232 ]]], shape=(1, 3, 5), dtype=float32)''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0b63",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Option 2 (for alternate dropout implementation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "08fa87",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "netActs from your MLPBlock are:\n",
      "tf.Tensor(\n",
      "[[[ 0.9135 -1.0447 -0.2246  0.706  -1.1197]\n",
      "  [ 1.7503 -0.6826 -1.4628  0.0423 -1.8769]\n",
      "  [ 0.2141 -0.0222  0.      0.0865  0.232 ]]], shape=(1, 3, 5), dtype=float32)\n",
      "and should be:\n",
      "tf.Tensor(\n",
      "[[[ 0.9135 -1.0447 -0.2246  0.706  -1.1197]\n",
      "  [ 1.7503 -0.6826 -1.4628  0.0423 -1.8769]\n",
      "  [ 0.2141 -0.0222  0.      0.0865  0.232 ]]], shape=(1, 3, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "x_test = tf.random.uniform(shape=(1, 3, 4))\n",
    "\n",
    "mlpblock = MLPBlock('testMLPBlock', units=5, prev_layer_or_block=None, dropout_rate=0.2)\n",
    "mlpblock.set_mode(is_training=True)\n",
    "test_net_acts = mlpblock(x_test)\n",
    "print('netActs from your MLPBlock are:')\n",
    "print(test_net_acts)\n",
    "print('and should be:')\n",
    "print('''tf.Tensor(\n",
    "[[[ 0.9135 -1.0447 -0.2246  0.706  -1.1197]\n",
    "  [ 1.7503 -0.6826 -1.4628  0.0423 -1.8769]\n",
    "  [ 0.2141 -0.0222  0.      0.0865  0.232 ]]], shape=(1, 3, 5), dtype=float32)''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b8fa",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Test: `MLPBlock` (Dropout 2/2)\n",
    "\n",
    "Prediction mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "ce17de",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "netActs from your MLPBlock are:\n",
      "tf.Tensor(\n",
      "[[[ 0.7308 -0.8358 -0.1797  0.5648 -0.8958]\n",
      "  [ 1.4003 -0.5461 -1.1703  0.0338 -1.5015]\n",
      "  [ 0.1713 -0.0177  0.0166  0.0692  0.1856]]], shape=(1, 3, 5), dtype=float32)\n",
      "and should be:\n",
      "tf.Tensor(\n",
      "[[[ 0.7308 -0.8358 -0.1797  0.5648 -0.8958]\n",
      "  [ 1.4003 -0.5461 -1.1702  0.0338 -1.5015]\n",
      "  [ 0.1713 -0.0177  0.0166  0.0692  0.1856]]], shape=(1, 3, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "mlpblock.set_mode(is_training=False)\n",
    "test_net_acts = mlpblock(x_test)\n",
    "print('netActs from your MLPBlock are:')\n",
    "print(test_net_acts)\n",
    "print('and should be:')\n",
    "print('''tf.Tensor(\n",
    "[[[ 0.7308 -0.8358 -0.1797  0.5648 -0.8958]\n",
    "  [ 1.4003 -0.5461 -1.1702  0.0338 -1.5015]\n",
    "  [ 0.1713 -0.0177  0.0166  0.0692  0.1856]]], shape=(1, 3, 5), dtype=float32)''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1c39",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3f. Implement `TransformerBlock`\n",
    "\n",
    "Now we are ready to implement the full Transformer Block, which is composed of a `MultiHeadAttentionBlock` followed by the `MLPBlock`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "0aef52",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from transformer_blocks import TransformerBlock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2c77",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Test: `TransformerBlock` (No dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "1219c6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "netActs from your Transformer Block are:\n",
      "tf.Tensor(\n",
      "[[[-1.5531 -1.3262 -2.4073  0.243   0.1851  0.4998]\n",
      "  [ 0.2843 -0.3698  1.5316  0.615   0.9175 -0.3186]\n",
      "  [-0.1368  0.7006  0.321  -0.6023  1.3685  0.0439]]\n",
      "\n",
      " [[ 0.0586  0.329  -0.9239 -0.9192  3.2321 -0.4438]\n",
      "  [-0.6011 -0.3067 -2.2542  0.3201 -0.159   1.432 ]\n",
      "  [ 0.0053  1.1205 -0.3437  1.2761  1.454   0.4725]]], shape=(2, 3, 6), dtype=float32)\n",
      "and should be:\n",
      "tf.Tensor(\n",
      "[[[-1.5531 -1.3262 -2.4073  0.243   0.1851  0.4998]\n",
      "  [ 0.2843 -0.3698  1.5316  0.615   0.9175 -0.3186]\n",
      "  [-0.1368  0.7006  0.321  -0.6023  1.3685  0.0439]]\n",
      "\n",
      " [[ 0.0586  0.329  -0.9239 -0.9192  3.2321 -0.4438]\n",
      "  [-0.6011 -0.3067 -2.2542  0.3201 -0.159   1.432 ]\n",
      "  [ 0.0053  1.1205 -0.3437  1.2761  1.454   0.4725]]], shape=(2, 3, 6), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "x_test = tf.random.uniform(shape=(2, 3, 6))\n",
    "\n",
    "tblock = TransformerBlock('testTBlock', units=6, num_heads=3, prev_layer_or_block=None, dropout_rate=0.)\n",
    "test_net_acts = tblock(x_test)\n",
    "print('netActs from your Transformer Block are:')\n",
    "print(test_net_acts)\n",
    "print('and should be:')\n",
    "print('''tf.Tensor(\n",
    "[[[-1.5531 -1.3262 -2.4073  0.243   0.1851  0.4998]\n",
    "  [ 0.2843 -0.3698  1.5316  0.615   0.9175 -0.3186]\n",
    "  [-0.1368  0.7006  0.321  -0.6023  1.3685  0.0439]]\n",
    "\n",
    " [[ 0.0586  0.329  -0.9239 -0.9192  3.2321 -0.4438]\n",
    "  [-0.6011 -0.3067 -2.2542  0.3201 -0.159   1.432 ]\n",
    "  [ 0.0053  1.1205 -0.3437  1.2761  1.454   0.4725]]], shape=(2, 3, 6), dtype=float32)''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5578b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Test: `TransformerBlock` (Dropout 1/2)\n",
    "\n",
    "Training mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "86476f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "netActs from your Transformer Block are:\n",
      "tf.Tensor(\n",
      "[[[ 1.6513  1.5017  0.0903  2.7346]\n",
      "  [ 0.303   0.2849 -0.2772  2.0979]\n",
      "  [ 0.7218  1.8296  0.0204  1.6906]]\n",
      "\n",
      " [[ 3.8468 -0.4212  0.532   0.16  ]\n",
      "  [ 0.7442 -0.5215  2.2846  1.2911]\n",
      "  [ 0.2736 -1.2184  0.0555  0.315 ]]], shape=(2, 3, 4), dtype=float32)\n",
      "and should be:\n",
      "tf.Tensor(\n",
      "[[[ 0.2805  0.9015 -0.1326  2.7713]\n",
      "  [ 1.4169  0.4118  0.9758  0.248 ]\n",
      "  [ 0.6692  1.8499  0.3252  2.3496]]\n",
      "\n",
      " [[ 0.9539 -2.6124  3.2987  1.1689]\n",
      "  [-1.9677  1.3901  0.0221  0.9654]\n",
      "  [ 1.056  -0.0272 -2.0798  0.2343]]], shape=(2, 3, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "x_test = tf.random.uniform(shape=(2, 3, 4))\n",
    "\n",
    "tblock = TransformerBlock('testTBlock', units=4, num_heads=2, prev_layer_or_block=None, dropout_rate=0.2)\n",
    "tblock.set_mode(is_training=True)\n",
    "test_net_acts = tblock(x_test)\n",
    "print('netActs from your Transformer Block are:')\n",
    "print(test_net_acts)\n",
    "print('and should be:')\n",
    "print('''tf.Tensor(\n",
    "[[[ 0.2805  0.9015 -0.1326  2.7713]\n",
    "  [ 1.4169  0.4118  0.9758  0.248 ]\n",
    "  [ 0.6692  1.8499  0.3252  2.3496]]\n",
    "\n",
    " [[ 0.9539 -2.6124  3.2987  1.1689]\n",
    "  [-1.9677  1.3901  0.0221  0.9654]\n",
    "  [ 1.056  -0.0272 -2.0798  0.2343]]], shape=(2, 3, 4), dtype=float32)''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5b14",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Option 2 (for alternate dropout implementation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "3d4680",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "netActs from your Transformer Block are:\n",
      "tf.Tensor(\n",
      "[[[ 1.6513  1.5017  0.0903  2.7346]\n",
      "  [ 0.303   0.2849 -0.2772  2.0979]\n",
      "  [ 0.7218  1.8296  0.0204  1.6906]]\n",
      "\n",
      " [[ 3.8468 -0.4212  0.532   0.16  ]\n",
      "  [ 0.7442 -0.5215  2.2846  1.2911]\n",
      "  [ 0.2736 -1.2184  0.0555  0.315 ]]], shape=(2, 3, 4), dtype=float32)\n",
      "and should be:\n",
      "tf.Tensor(\n",
      "[[[ 1.6513  1.5017  0.0903  2.7346]\n",
      "  [ 0.303   0.2849 -0.2772  2.0979]\n",
      "  [ 0.7218  1.8296  0.0204  1.6906]]\n",
      "\n",
      " [[ 3.8468 -0.4212  0.532   0.16  ]\n",
      "  [ 0.7442 -0.5215  2.2846  1.2911]\n",
      "  [ 0.2736 -1.2184  0.0555  0.315 ]]], shape=(2, 3, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "x_test = tf.random.uniform(shape=(2, 3, 4))\n",
    "\n",
    "tblock = TransformerBlock('testTBlock', units=4, num_heads=2, prev_layer_or_block=None, dropout_rate=0.2)\n",
    "tblock.set_mode(is_training=True)\n",
    "test_net_acts = tblock(x_test)\n",
    "print('netActs from your Transformer Block are:')\n",
    "print(test_net_acts)\n",
    "print('and should be:')\n",
    "print('''tf.Tensor(\n",
    "[[[ 1.6513  1.5017  0.0903  2.7346]\n",
    "  [ 0.303   0.2849 -0.2772  2.0979]\n",
    "  [ 0.7218  1.8296  0.0204  1.6906]]\n",
    "\n",
    " [[ 3.8468 -0.4212  0.532   0.16  ]\n",
    "  [ 0.7442 -0.5215  2.2846  1.2911]\n",
    "  [ 0.2736 -1.2184  0.0555  0.315 ]]], shape=(2, 3, 4), dtype=float32)''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fd13",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Test: `TransformerBlock` (Dropout 2/2)\n",
    "\n",
    "Prediction mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "175330",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "netActs from your Transformer Block are:\n",
      "tf.Tensor(\n",
      "[[[ 1.2375  1.3978  0.1956  1.901 ]\n",
      "  [ 0.9879  1.2677  0.2901  2.2666]\n",
      "  [ 0.5847  1.0634  0.1622  1.8624]]\n",
      "\n",
      " [[ 1.0252 -0.8074  2.0755  0.7679]\n",
      "  [-0.996   1.2571  0.741   0.7996]\n",
      "  [-0.2824  1.1839 -0.3884 -0.1844]]], shape=(2, 3, 4), dtype=float32)\n",
      "and should be:\n",
      "tf.Tensor(\n",
      "[[[ 1.2375  1.3978  0.1956  1.901 ]\n",
      "  [ 0.9879  1.2677  0.2901  2.2666]\n",
      "  [ 0.5847  1.0634  0.1622  1.8624]]\n",
      "\n",
      " [[ 1.0252 -0.8074  2.0755  0.7679]\n",
      "  [-0.996   1.2571  0.741   0.7996]\n",
      "  [-0.2824  1.1839 -0.3884 -0.1844]]], shape=(2, 3, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tblock.set_mode(is_training=False)\n",
    "test_net_acts = tblock(x_test)\n",
    "print('netActs from your Transformer Block are:')\n",
    "print(test_net_acts)\n",
    "print('and should be:')\n",
    "print('''tf.Tensor(\n",
    "[[[ 1.2375  1.3978  0.1956  1.901 ]\n",
    "  [ 0.9879  1.2677  0.2901  2.2666]\n",
    "  [ 0.5847  1.0634  0.1622  1.8624]]\n",
    "\n",
    " [[ 1.0252 -0.8074  2.0755  0.7679]\n",
    "  [-0.996   1.2571  0.741   0.7996]\n",
    "  [-0.2824  1.1839 -0.3884 -0.1844]]], shape=(2, 3, 4), dtype=float32)''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3e3e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Task 4: Positional encoding\n",
    "\n",
    "Although we organize each sample as an ordered list of `T` tokens, the attention mechanism does not \"see\" or consider that significance of the position of the characters in the sequence. This hinders the ability to predict the next character. For example, in the addition dataset, The `'+'` character always ONLY appears in index 1 or 2 (*because each operand can only be 1-2 digits long*). If you are predicting token at position 1-2, it should be helpful to take into account that `'+'` is a plausible/likely prediction! Conversely, the transformer should learn that it is unlike that `'+'` appears anywhere else other than in position 1-2. \n",
    "\n",
    "In transformers, we tend to inject a \"give-away, special code\" in the netActs that correlates to the position in the sequence so that the transformer can learn not only what character should come next given the set of previous characters sequence, but also the position of those characters in the sequence.\n",
    "\n",
    "We use a trigonometric function to inject these position codes into the netAct:\n",
    "\n",
    "$$\n",
    "\\text{PE}_{tj} = \n",
    "\\begin{cases}\n",
    "\\sin\\left(\\omega_k t\\right) & \\text{if neuron j is an even number} \\\\ \\\\\n",
    "\\cos\\left(\\omega_k t\\right) & \\text{if neuron j is an odd number}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "where $t$ indexes the position in the sequence (out of `T` positions), $j$ indexes the neuron in the `Embedding` layer (out of `H_embed` total), $k = 2*\\left\\lfloor j/2 \\right\\rfloor$ — (i.e. each **even numbered** embedding layer neuron `j` (0, 2, 4, 6, etc.) and its right neighbor `j+1` (e.g. 1, 3, 5, 7, etc.) share the same frequency $\\omega_k$), and the frequency term is defined as follows:\n",
    "\n",
    "$$\n",
    "\\omega_k = \\dfrac{1}{10000^{k / H_{\\text{embed}}}}\n",
    "$$\n",
    "\n",
    "The netIn value in the PositionalEncoding layer is just the input to the layer `x` plus the position encoding matrix $\\text{PE}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca70ca",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 4a. Implement `PositionalEncoding` layer\n",
    "\n",
    "The class is in `transformer_layers.py`. Test your implementation below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "218921",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from transformer_layers import PositionalEncoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d51b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Test: `PositionalEncoding` layer (position encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "4839c7",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your positional encoding matrix is:\n",
      "tf.Tensor(\n",
      "[[[ 0.      1.      0.      1.      0.      1.    ]\n",
      "  [ 0.8415  0.5403  0.0464  0.9989  0.0022  1.    ]\n",
      "  [ 0.9093 -0.4161  0.0927  0.9957  0.0043  1.    ]\n",
      "  [ 0.1411 -0.99    0.1388  0.9903  0.0065  1.    ]\n",
      "  [-0.7568 -0.6536  0.1846  0.9828  0.0086  1.    ]\n",
      "  [-0.9589  0.2837  0.23    0.9732  0.0108  0.9999]\n",
      "  [-0.2794  0.9602  0.2749  0.9615  0.0129  0.9999]\n",
      "  [ 0.657   0.7539  0.3192  0.9477  0.0151  0.9999]\n",
      "  [ 0.9894 -0.1455  0.3629  0.9318  0.0172  0.9999]\n",
      "  [ 0.4121 -0.9111  0.4057  0.914   0.0194  0.9998]]], shape=(1, 10, 6), dtype=float32)\n",
      "and it should be:\n",
      "tf.Tensor(\n",
      "[[[ 0.      1.      0.      1.      0.      1.    ]\n",
      "  [ 0.8415  0.5403  0.0464  0.9989  0.0022  1.    ]\n",
      "  [ 0.9093 -0.4161  0.0927  0.9957  0.0043  1.    ]\n",
      "  [ 0.1411 -0.99    0.1388  0.9903  0.0065  1.    ]\n",
      "  [-0.7568 -0.6536  0.1846  0.9828  0.0086  1.    ]\n",
      "  [-0.9589  0.2837  0.23    0.9732  0.0108  0.9999]\n",
      "  [-0.2794  0.9602  0.2749  0.9615  0.0129  0.9999]\n",
      "  [ 0.657   0.7539  0.3192  0.9477  0.0151  0.9999]\n",
      "  [ 0.9894 -0.1455  0.3629  0.9318  0.0172  0.9999]\n",
      "  [ 0.4121 -0.9111  0.4057  0.914   0.0194  0.9998]]], shape=(1, 10, 6), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "test_pe_lay = PositionalEncoding('testPELayer', embed_dim=6, prev_layer_or_block=None)\n",
    "pe_mat = test_pe_lay.create_position_encoding(embed_dim=6, seq_len=10)\n",
    "print('Your positional encoding matrix is:')\n",
    "print(pe_mat)\n",
    "print('and it should be:')\n",
    "print('''tf.Tensor(\n",
    "[[[ 0.      1.      0.      1.      0.      1.    ]\n",
    "  [ 0.8415  0.5403  0.0464  0.9989  0.0022  1.    ]\n",
    "  [ 0.9093 -0.4161  0.0927  0.9957  0.0043  1.    ]\n",
    "  [ 0.1411 -0.99    0.1388  0.9903  0.0065  1.    ]\n",
    "  [-0.7568 -0.6536  0.1846  0.9828  0.0086  1.    ]\n",
    "  [-0.9589  0.2837  0.23    0.9732  0.0108  0.9999]\n",
    "  [-0.2794  0.9602  0.2749  0.9615  0.0129  0.9999]\n",
    "  [ 0.657   0.7539  0.3192  0.9477  0.0151  0.9999]\n",
    "  [ 0.9894 -0.1455  0.3629  0.9318  0.0172  0.9999]\n",
    "  [ 0.4121 -0.9111  0.4057  0.914   0.0194  0.9998]]], shape=(1, 10, 6), dtype=float32)''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b9b9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Test: `PositionalEncoding` layer (`net_in`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "433f9a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your netIns are:\n",
      "tf.Tensor(\n",
      "[[[-0.0042  0.9941  0.0007  1.0012 -0.0017  1.0062]\n",
      "  [ 0.8413  0.5503  0.0503  0.9914  0.0064  1.0032]\n",
      "  [ 0.9107 -0.4189  0.0911  0.9983  0.0126  1.0032]\n",
      "  [ 0.1478 -0.9983  0.1344  0.9806  0.011   1.0053]\n",
      "  [-0.7532 -0.653   0.1897  0.9738 -0.0004  1.005 ]\n",
      "  [-0.9655  0.2799  0.2258  0.9652  0.0041  1.0053]\n",
      "  [-0.2777  0.9698  0.2832  0.9543  0.0049  1.002 ]\n",
      "  [ 0.6505  0.7543  0.3289  0.9412  0.006   1.0018]\n",
      "  [ 0.9906 -0.1394  0.3645  0.9239  0.0261  0.9955]\n",
      "  [ 0.4132 -0.9155  0.3973  0.9118  0.0108  0.9907]]\n",
      "\n",
      " [[ 0.0085  1.0075 -0.0006  0.9994  0.0026  1.0046]\n",
      "  [ 0.8502  0.5375  0.0405  1.001   0.0002  1.0018]\n",
      "  [ 0.9167 -0.4098  0.0828  0.9905 -0.0017  0.9908]\n",
      "  [ 0.1507 -0.9966  0.1428  0.9951  0.0133  1.0047]\n",
      "  [-0.7522 -0.6599  0.1893  0.9766  0.0103  0.9907]\n",
      "  [-0.9555  0.2854  0.22    0.9727  0.0198  1.0046]\n",
      "  [-0.2776  0.957   0.2803  0.9527  0.0163  0.9994]\n",
      "  [ 0.6483  0.7633  0.3185  0.9477  0.0073  1.0045]\n",
      "  [ 0.9945 -0.1469  0.3538  0.9326  0.0105  0.9978]\n",
      "  [ 0.4134 -0.9191  0.4146  0.9103  0.0187  1.0016]]], shape=(2, 10, 6), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(0)\n",
    "test_x = tf.random.uniform(shape=(2, 10, 6), minval=-0.01, maxval=0.01)\n",
    "test_pe_lay = PositionalEncoding('testPELayer', embed_dim=6, prev_layer_or_block=None)\n",
    "test_netins = test_pe_lay.compute_net_input(test_x)\n",
    "print('Your netIns are:')\n",
    "print(test_netins)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0793",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The cell above should output:\n",
    "\n",
    "```\n",
    "Your netIns are:\n",
    "tf.Tensor(\n",
    "[[[-0.0042  0.9941  0.0007  1.0012 -0.0017  1.0062]\n",
    "  [ 0.8413  0.5503  0.0503  0.9914  0.0064  1.0032]\n",
    "  [ 0.9107 -0.4189  0.0911  0.9983  0.0126  1.0032]\n",
    "  [ 0.1478 -0.9983  0.1344  0.9806  0.011   1.0053]\n",
    "  [-0.7532 -0.653   0.1897  0.9738 -0.0004  1.005 ]\n",
    "  [-0.9655  0.2799  0.2258  0.9652  0.0041  1.0053]\n",
    "  [-0.2777  0.9698  0.2832  0.9543  0.0049  1.002 ]\n",
    "  [ 0.6505  0.7543  0.3289  0.9412  0.006   1.0018]\n",
    "  [ 0.9906 -0.1394  0.3645  0.9239  0.0261  0.9955]\n",
    "  [ 0.4132 -0.9155  0.3973  0.9118  0.0108  0.9907]]\n",
    "\n",
    " [[ 0.0085  1.0075 -0.0006  0.9994  0.0026  1.0046]\n",
    "  [ 0.8502  0.5375  0.0405  1.001   0.0002  1.0018]\n",
    "  [ 0.9167 -0.4098  0.0828  0.9905 -0.0017  0.9908]\n",
    "  [ 0.1507 -0.9966  0.1428  0.9951  0.0133  1.0047]\n",
    "  [-0.7522 -0.6599  0.1893  0.9766  0.0103  0.9907]\n",
    "  [-0.9555  0.2854  0.22    0.9727  0.0198  1.0046]\n",
    "  [-0.2776  0.957   0.2803  0.9527  0.0163  0.9994]\n",
    "  [ 0.6483  0.7633  0.3185  0.9477  0.0073  1.0045]\n",
    "  [ 0.9945 -0.1469  0.3538  0.9326  0.0105  0.9978]\n",
    "  [ 0.4134 -0.9191  0.4146  0.9103  0.0187  1.0016]]], shape=(2, 10, 6), dtype=float32)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "03a93b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[-0.0042  0.9941  0.0007  1.0012 -0.0017  1.0062]\n",
      "  [ 0.8413  0.5503  0.0503  0.9914  0.0064  1.0032]\n",
      "  [ 0.9107 -0.4189  0.0911  0.9983  0.0126  1.0032]\n",
      "  [ 0.1478 -0.9983  0.1344  0.9806  0.011   1.0053]\n",
      "  [-0.7532 -0.653   0.1897  0.9738 -0.0004  1.005 ]\n",
      "  [-0.9655  0.2799  0.2258  0.9652  0.0041  1.0053]\n",
      "  [-0.2777  0.9698  0.2832  0.9543  0.0049  1.002 ]\n",
      "  [ 0.6505  0.7543  0.3289  0.9412  0.006   1.0018]\n",
      "  [ 0.9906 -0.1394  0.3645  0.9239  0.0261  0.9955]\n",
      "  [ 0.4132 -0.9155  0.3973  0.9118  0.0108  0.9907]]\n",
      "\n",
      " [[ 0.0085  1.0075 -0.0006  0.9994  0.0026  1.0046]\n",
      "  [ 0.8502  0.5375  0.0405  1.001   0.0002  1.0018]\n",
      "  [ 0.9167 -0.4098  0.0828  0.9905 -0.0017  0.9908]\n",
      "  [ 0.1507 -0.9966  0.1428  0.9951  0.0133  1.0047]\n",
      "  [-0.7522 -0.6599  0.1893  0.9766  0.0103  0.9907]\n",
      "  [-0.9555  0.2854  0.22    0.9727  0.0198  1.0046]\n",
      "  [-0.2776  0.957   0.2803  0.9527  0.0163  0.9994]\n",
      "  [ 0.6483  0.7633  0.3185  0.9477  0.0073  1.0045]\n",
      "  [ 0.9945 -0.1469  0.3538  0.9326  0.0105  0.9978]\n",
      "  [ 0.4134 -0.9191  0.4146  0.9103  0.0187  1.0016]]], shape=(2, 10, 6), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[-0.0042 -0.0059  0.0007  0.0012 -0.0017  0.0062]\n",
      "  [-0.0001  0.01    0.0039 -0.0075  0.0042  0.0032]\n",
      "  [ 0.0014 -0.0027 -0.0016  0.0026  0.0083  0.0032]\n",
      "  [ 0.0067 -0.0083 -0.0044 -0.0097  0.0045  0.0053]\n",
      "  [ 0.0036  0.0007  0.0051 -0.0091 -0.009   0.005 ]\n",
      "  [-0.0065 -0.0038 -0.0042 -0.008  -0.0067  0.0054]\n",
      "  [ 0.0017  0.0096  0.0083 -0.0072 -0.008   0.0021]\n",
      "  [-0.0064  0.0004  0.0096 -0.0065 -0.0091  0.002 ]\n",
      "  [ 0.0013  0.0061  0.0017 -0.0079  0.0089 -0.0043]\n",
      "  [ 0.0011 -0.0044 -0.0084 -0.0022 -0.0086 -0.0092]]\n",
      "\n",
      " [[ 0.0085  0.0075 -0.0006 -0.0006  0.0026  0.0046]\n",
      "  [ 0.0087 -0.0028 -0.0059  0.0021 -0.002   0.0018]\n",
      "  [ 0.0074  0.0064 -0.0099 -0.0052 -0.006  -0.0092]\n",
      "  [ 0.0096 -0.0066  0.004   0.0047  0.0069  0.0047]\n",
      "  [ 0.0046 -0.0062  0.0047 -0.0062  0.0017 -0.0092]\n",
      "  [ 0.0034  0.0017 -0.01   -0.0005  0.0091  0.0047]\n",
      "  [ 0.0018 -0.0032  0.0054 -0.0088  0.0033 -0.0005]\n",
      "  [-0.0086  0.0094 -0.0008  0.     -0.0077  0.0046]\n",
      "  [ 0.0051 -0.0014 -0.0091  0.0008 -0.0068 -0.0021]\n",
      "  [ 0.0013 -0.0079  0.009  -0.0037 -0.0007  0.0018]]], shape=(2, 10, 6), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(test_netins)\n",
    "print(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5f90",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 4b. Questions\n",
    "\n",
    "**Question 2:** Compare the `net_in` output from the last test above with the original input to position encoding matrix `pe_mat` from above. Point out specifically how the `net_in` clearly demonstrates position coding of the input `test_x`. *Hint: It might help to also print out `test_x`.*\n",
    "\n",
    "**Question 3:** In the cell below, make a heatmap showing the position encoding obtained when the embedding dimension is `100` and the sequence length is `50` tokens long. **Properly label the heatmap and clearly explain what the patterns in the heatmap mean.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da00f2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Answer 2:** the test_x values are very small, so we can essentially see that our net_in is heavily influenced by the pe_mat that is being added to it... We see when t=0 (in both batches), there is the nice pattern of adding 1, adding 0, 1, 0, 1, 0. These oscillations remain for each T, however we see them ranging in their values more drastically as t becomes larger and larger... demonstrating that we should/the network should -- be able to identity different 't's\n",
    "\n",
    "**Answer 3:** We see for the first timesteps, we have fast osilations, however, as we go down, the wave 'spreads out,' so for those times, the network will know it is later by understanding an increases to all the embedding dimension values, but slowlllly increasing across the 100 H values. Now it can make sense of the positions in the sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "94d3e3",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "execution_count": 0,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe_layer = PositionalEncoding('pe100', embed_dim=100, prev_layer_or_block=None)\n",
    "\n",
    "#We just want PE, so wewill plug in 0\n",
    "zero_input = tf.zeros((1, 50, 100), dtype=tf.float32)\n",
    "net_in = pe_layer.compute_net_input(zero_input)(1, 50, 100)\n",
    "\n",
    "pos_encoding = net_in[0].numpy()#(50, 100)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(pos_encoding, aspect='auto')\n",
    "plt.xlabel('Embedding Dimension (j)')\n",
    "plt.ylabel('Sequence Position (t)')\n",
    "plt.title('Positional Encoding Heatmap (T=50, H=100)')\n",
    "plt.colorbar(label='PE value')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710345",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 4c. Implement `PositionalEncodingBlock`\n",
    "\n",
    "In a transformer neural network, the positional encoding layer is usually followed by a `Dropout` layer. Let's make a block to bundle these two layers together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "f3052a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from transformer_blocks import PositionalEncodingBlock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46acb",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Test: `PositionalEncodingBlock` (No dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "75bb08",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "netActs from your PE Block are:\n",
      "tf.Tensor(\n",
      "[[[ 0.1651  1.9015  0.631   1.4345]\n",
      "  [ 1.1334  1.1828  0.9858  1.435 ]\n",
      "  [ 1.5694  0.1887  0.6566  1.6142]\n",
      "  [ 1.0305 -0.3622  0.562   1.0255]\n",
      "  [-0.3159 -0.401   0.9262  1.8865]]\n",
      "\n",
      " [[ 0.7873  1.0596  0.0711  1.3084]\n",
      "  [ 1.0927  1.4488  0.4815  1.2423]\n",
      "  [ 1.5423  0.1699  0.93    1.5699]\n",
      "  [ 0.6376 -0.3961  0.5714  1.4425]\n",
      "  [-0.4643  0.0803  0.9597  1.6677]]], shape=(2, 5, 4), dtype=float32)\n",
      "and should be:\n",
      "tf.Tensor(\n",
      "[[[ 0.1651  1.9015  0.631   1.4345]\n",
      "  [ 1.1334  1.1828  0.9858  1.435 ]\n",
      "  [ 1.5694  0.1887  0.6566  1.6142]\n",
      "  [ 1.0305 -0.3622  0.562   1.0255]\n",
      "  [-0.3159 -0.401   0.9262  1.8865]]\n",
      "\n",
      " [[ 0.7873  1.0596  0.0711  1.3084]\n",
      "  [ 1.0927  1.4488  0.4815  1.2423]\n",
      "  [ 1.5423  0.1699  0.93    1.5699]\n",
      "  [ 0.6376 -0.3961  0.5714  1.4425]\n",
      "  [-0.4643  0.0803  0.9597  1.6677]]], shape=(2, 5, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "x_test = tf.random.uniform(shape=(2, 5, 4))\n",
    "\n",
    "peblock = PositionalEncodingBlock('testPElock', embed_dim=4, prev_layer_or_block=None, dropout_rate=0.)\n",
    "test_net_acts = peblock(x_test)\n",
    "print('netActs from your PE Block are:')\n",
    "print(test_net_acts)\n",
    "print('and should be:')\n",
    "print('''tf.Tensor(\n",
    "[[[ 0.1651  1.9015  0.631   1.4345]\n",
    "  [ 1.1334  1.1828  0.9858  1.435 ]\n",
    "  [ 1.5694  0.1887  0.6566  1.6142]\n",
    "  [ 1.0305 -0.3622  0.562   1.0255]\n",
    "  [-0.3159 -0.401   0.9262  1.8865]]\n",
    "\n",
    " [[ 0.7873  1.0596  0.0711  1.3084]\n",
    "  [ 1.0927  1.4488  0.4815  1.2423]\n",
    "  [ 1.5423  0.1699  0.93    1.5699]\n",
    "  [ 0.6376 -0.3961  0.5714  1.4425]\n",
    "  [-0.4643  0.0803  0.9597  1.6677]]], shape=(2, 5, 4), dtype=float32)''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603f32",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Test: `PositionalEncodingBlock` (Dropout 1/2)\n",
    "\n",
    "Training mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "b960b5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "netActs from your PE Block are:\n",
      "tf.Tensor(\n",
      "[[[ 0.3303  0.      0.      2.8691]\n",
      "  [ 2.2668  0.      0.      2.8701]\n",
      "  [ 0.      0.3775  0.      3.2285]\n",
      "  [ 2.0609 -0.7245  0.      0.    ]\n",
      "  [-0.6319 -0.8019  1.8524  3.773 ]]\n",
      "\n",
      " [[ 0.      2.1191  0.      2.6168]\n",
      "  [ 2.1853  0.      0.963   0.    ]\n",
      "  [ 3.0846  0.3398  1.86    3.1399]\n",
      "  [ 0.     -0.7922  1.1429  2.8849]\n",
      "  [-0.9286  0.      0.      3.3354]]], shape=(2, 5, 4), dtype=float32)\n",
      "and should be:\n",
      "tf.Tensor(\n",
      "[[[ 0.      3.803   1.2619  0.    ]\n",
      "  [ 0.      2.3656  1.9716  0.    ]\n",
      "  [ 3.1388  0.      1.3133  0.    ]\n",
      "  [ 0.     -0.      1.1239  2.0511]\n",
      "  [-0.     -0.      0.      0.    ]]\n",
      "\n",
      " [[ 1.5746  0.      0.1422  0.    ]\n",
      "  [ 0.      2.8975  0.      2.4847]\n",
      "  [ 0.      0.      0.      0.    ]\n",
      "  [ 1.2751 -0.      0.      0.    ]\n",
      "  [-0.      0.1606  1.9194  0.    ]]], shape=(2, 5, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "x_test = tf.random.uniform(shape=(2, 5, 4))\n",
    "\n",
    "peblock = PositionalEncodingBlock('testPElock', embed_dim=4, prev_layer_or_block=None, dropout_rate=0.5)\n",
    "peblock.set_mode(is_training=True)\n",
    "test_net_acts = peblock(x_test)\n",
    "print('netActs from your PE Block are:')\n",
    "print(test_net_acts)\n",
    "print('and should be:')\n",
    "print('''tf.Tensor(\n",
    "[[[ 0.      3.803   1.2619  0.    ]\n",
    "  [ 0.      2.3656  1.9716  0.    ]\n",
    "  [ 3.1388  0.      1.3133  0.    ]\n",
    "  [ 0.     -0.      1.1239  2.0511]\n",
    "  [-0.     -0.      0.      0.    ]]\n",
    "\n",
    " [[ 1.5746  0.      0.1422  0.    ]\n",
    "  [ 0.      2.8975  0.      2.4847]\n",
    "  [ 0.      0.      0.      0.    ]\n",
    "  [ 1.2751 -0.      0.      0.    ]\n",
    "  [-0.      0.1606  1.9194  0.    ]]], shape=(2, 5, 4), dtype=float32)''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35b69",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Option 2 (for alternate dropout implementation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "4b8f51",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "netActs from your PE Block are:\n",
      "tf.Tensor(\n",
      "[[[ 0.3303  0.      0.      2.8691]\n",
      "  [ 2.2668  0.      0.      2.8701]\n",
      "  [ 0.      0.3775  0.      3.2285]\n",
      "  [ 2.0609 -0.7245  0.      0.    ]\n",
      "  [-0.6319 -0.8019  1.8524  3.773 ]]\n",
      "\n",
      " [[ 0.      2.1191  0.      2.6168]\n",
      "  [ 2.1853  0.      0.963   0.    ]\n",
      "  [ 3.0846  0.3398  1.86    3.1399]\n",
      "  [ 0.     -0.7922  1.1429  2.8849]\n",
      "  [-0.9286  0.      0.      3.3354]]], shape=(2, 5, 4), dtype=float32)\n",
      "and should be:\n",
      "tf.Tensor(\n",
      "[[[ 0.3303  0.      0.      2.8691]\n",
      "  [ 2.2668  0.      0.      2.8701]\n",
      "  [ 0.      0.3775  0.      3.2285]\n",
      "  [ 2.0609 -0.7245  0.      0.    ]\n",
      "  [-0.6319 -0.8019  1.8524  3.773 ]]\n",
      "\n",
      " [[ 0.      2.1191  0.      2.6168]\n",
      "  [ 2.1853  0.      0.963   0.    ]\n",
      "  [ 3.0846  0.3398  1.86    3.1399]\n",
      "  [ 0.     -0.7922  1.1429  2.8849]\n",
      "  [-0.9286  0.      0.      3.3354]]], shape=(2, 5, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "x_test = tf.random.uniform(shape=(2, 5, 4))\n",
    "\n",
    "peblock = PositionalEncodingBlock('testPElock', embed_dim=4, prev_layer_or_block=None, dropout_rate=0.5)\n",
    "peblock.set_mode(is_training=True)\n",
    "test_net_acts = peblock(x_test)\n",
    "print('netActs from your PE Block are:')\n",
    "print(test_net_acts)\n",
    "print('and should be:')\n",
    "print('''tf.Tensor(\n",
    "[[[ 0.3303  0.      0.      2.8691]\n",
    "  [ 2.2668  0.      0.      2.8701]\n",
    "  [ 0.      0.3775  0.      3.2285]\n",
    "  [ 2.0609 -0.7245  0.      0.    ]\n",
    "  [-0.6319 -0.8019  1.8524  3.773 ]]\n",
    "\n",
    " [[ 0.      2.1191  0.      2.6168]\n",
    "  [ 2.1853  0.      0.963   0.    ]\n",
    "  [ 3.0846  0.3398  1.86    3.1399]\n",
    "  [ 0.     -0.7922  1.1429  2.8849]\n",
    "  [-0.9286  0.      0.      3.3354]]], shape=(2, 5, 4), dtype=float32)''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc1db",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Test: `PositionalEncodingBlock` (Dropout 2/2)\n",
    "\n",
    "Prediction mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "389cee",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "netActs from your PE Block are:\n",
      "tf.Tensor(\n",
      "[[[ 0.1651  1.9015  0.631   1.4345]\n",
      "  [ 1.1334  1.1828  0.9858  1.435 ]\n",
      "  [ 1.5694  0.1887  0.6566  1.6142]\n",
      "  [ 1.0305 -0.3622  0.562   1.0255]\n",
      "  [-0.3159 -0.401   0.9262  1.8865]]\n",
      "\n",
      " [[ 0.7873  1.0596  0.0711  1.3084]\n",
      "  [ 1.0927  1.4488  0.4815  1.2423]\n",
      "  [ 1.5423  0.1699  0.93    1.5699]\n",
      "  [ 0.6376 -0.3961  0.5714  1.4425]\n",
      "  [-0.4643  0.0803  0.9597  1.6677]]], shape=(2, 5, 4), dtype=float32)\n",
      "and should be:\n",
      "tf.Tensor(\n",
      "[[[ 0.1651  1.9015  0.631   1.4345]\n",
      "  [ 1.1334  1.1828  0.9858  1.435 ]\n",
      "  [ 1.5694  0.1887  0.6566  1.6142]\n",
      "  [ 1.0305 -0.3622  0.562   1.0255]\n",
      "  [-0.3159 -0.401   0.9262  1.8865]]\n",
      "\n",
      " [[ 0.7873  1.0596  0.0711  1.3084]\n",
      "  [ 1.0927  1.4488  0.4815  1.2423]\n",
      "  [ 1.5423  0.1699  0.93    1.5699]\n",
      "  [ 0.6376 -0.3961  0.5714  1.4425]\n",
      "  [-0.4643  0.0803  0.9597  1.6677]]], shape=(2, 5, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "peblock.set_mode(is_training=False)\n",
    "test_net_acts = peblock(x_test)\n",
    "print('netActs from your PE Block are:')\n",
    "print(test_net_acts)\n",
    "print('and should be:')\n",
    "print('''tf.Tensor(\n",
    "[[[ 0.1651  1.9015  0.631   1.4345]\n",
    "  [ 1.1334  1.1828  0.9858  1.435 ]\n",
    "  [ 1.5694  0.1887  0.6566  1.6142]\n",
    "  [ 1.0305 -0.3622  0.562   1.0255]\n",
    "  [-0.3159 -0.401   0.9262  1.8865]]\n",
    "\n",
    " [[ 0.7873  1.0596  0.0711  1.3084]\n",
    "  [ 1.0927  1.4488  0.4815  1.2423]\n",
    "  [ 1.5423  0.1699  0.93    1.5699]\n",
    "  [ 0.6376 -0.3961  0.5714  1.4425]\n",
    "  [-0.4643  0.0803  0.9597  1.6677]]], shape=(2, 5, 4), dtype=float32)''')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "/usr/bin/python3",
    "-m",
    "ipykernel",
    "--HistoryManager.enabled=False",
    "--matplotlib=inline",
    "-c",
    "%config InlineBackend.figure_formats = set(['retina'])\nimport matplotlib; matplotlib.rcParams['figure.figsize'] = (12, 7)",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3 (system-wide)",
   "env": {
   },
   "language": "python",
   "metadata": {
    "cocalc": {
     "description": "Python 3 programming language",
     "priority": 100,
     "url": "https://www.python.org/"
    }
   },
   "name": "python3",
   "resource_dir": "/ext/jupyter/kernels/python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}